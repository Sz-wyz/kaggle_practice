{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据挖掘的五大流程：\n",
    "##### 1. 获取数据\n",
    "##### 2. 数据预处理\n",
    "数据预处理是从数据中检测，纠正或删除损坏，不准确或不适用于模型的记录的过程可能面对的问题有：数据类型不同，比如有的是文字，有的是数字，有的含时间序列，有的连续，有的间断。也可能，数据的质量不行，有噪声，有异常，有缺失，数据出错，量纲不一，有重复，数据是偏态，数据量太大或太小数据预处理的目的：让数据适应模型，匹配模型的需求\n",
    "##### 3. 特征工程\n",
    "特征工程是将原始数据转换为更能代表预测模型的潜在问题的特征的过程，可以通过挑选最相关的特征，提取特征以及创造特征来实现。其中创造特征又经常以降维算法的方式实现。可能面对的问题有：特征之间有相关性，特征和标签无关，特征太多或太小，或者干脆就无法表现出应有的数据现象或无法展示数据的真实面貌特征工程的目的：1) 降低计算成本，2) 提升模型上限\n",
    "##### 4. 建模\n",
    "测试模型并预测出结果\n",
    "##### 5. 上线\n",
    "验证模型效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn中的数据预处理和特征工程\n",
    "##### 模块preprocessing：几乎包含数据预处理的所有内容\n",
    "##### 模块Impute：填补缺失值专用\n",
    "##### 模块feature_selection：包含特征选择的各种方法的实践\n",
    "##### 模块decomposition：包含降维算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括中心化处理和缩放处理。中心化的本质是让所有记录减去一个固定值，即让数据处于某一位置。缩放的本质是通过除以一个固定值，将数据固定在某个范围内，取对数也是一种缩放。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing.MinMaxScaler 数据归一化\n",
    "重要参数 feature_range(控制我们希望数据压缩到的范围，默认是[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0 -1.0   2\n",
       "1 -0.5   6\n",
       "2  0.0  10\n",
       "3  1.0  18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[-1,2],[-0.5,6],[0,10],[1,18]]\n",
    "import pandas as pd\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现归一化\n",
    "scaler = MinMaxScaler() #实例化\n",
    "scaler = scaler.fit(data) #fit.在这里的本质是生成min和max\n",
    "result = scaler.transform(data) #通过结果导出结果\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ = scaler.fit_transform(data) #训练和导出结果一步达成\n",
    "scaler.inverse_transform(result_) #将归一化后的结果逆转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用MinMaxScaler的参数feature_range实现归一化【0,1】以外的范围中\n",
    "data = [[-1,2],[-0.5,6],[0,10],[1,18]]\n",
    "scaler = MinMaxScaler(feature_range=[5,10]) #依然实例化\n",
    "result = scaler.fit_transform(data) #fit_transform一步导出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.  ,  5.  ],\n",
       "       [ 6.25,  6.25],\n",
       "       [ 7.5 ,  7.5 ],\n",
       "       [10.  , 10.  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "当x中的特征数量非常多的时候，fit会报错并表示，数据量太大了计算不了\n",
    "此时使用partial_fit作为训练接口\n",
    "scaler = scaler.partial_fit(data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing.StandardScaler\n",
    "当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分布），而这个过程，就叫做数据标准化(Standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler.mean:[-0.125  9.   ]\n",
      "scaler.var:[ 0.546875 35.      ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[-1,2],[-0.5,6],[0,10],[1,18]]\n",
    "\n",
    "scaler = StandardScaler() #实例化\n",
    "scaler.fit(data) #fit 本质是生成均值和方差\n",
    "\n",
    "print('scaler.mean:{}'.format(scaler.mean_)) #查看均值属性mean_\n",
    "print('scaler.var:{}'.format(scaler.var_)) #查看方差属性var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_std.mean:0.0\n",
      "x_std.std：1.0\n"
     ]
    }
   ],
   "source": [
    "x_std = scaler.transform(data) #通过接口导出结果\n",
    "print('x_std.mean:{}'.format(x_std.mean())) #导出的结果是一个数组 用mean()查看均值\n",
    "print('x_std.std：{}'.format(x_std.std())) #用std查看方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18321596, -1.18321596],\n",
       "       [-0.50709255, -0.50709255],\n",
       "       [ 0.16903085,  0.16903085],\n",
       "       [ 1.52127766,  1.52127766]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(data) #用接口一步达成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(x_std) #使用inverse_transform逆转标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### StandardScaler和MinMaxScaler选哪个？\n",
    "看情况。大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。\n",
    "##### MinMaxScaler \n",
    "在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。\n",
    "##### 建议先试试看StandardScaler，效果不好换MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选用分位数来无量纲化，此时使用RobustScaler。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](1579419014(1).jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r'Narrativedata.csv',index_col=0) #index_col 请把第0列当成索引\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### impute.SimpleImputer\n",
    "classsklearn.impute.SimpleImputer(missing_values=nan, strategy=’mean’, fill_value=None, verbose=0,copy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'四个重要参数：\\nmissing_values:告诉SimpleImputer,数据中的缺失值长什么样，默认np.nan \\nstrategy:我们填补缺失值的策略，默认均值。\\n         mean,使用均值（仅对数值型特征可用）\\n         median,使用中值填补（仅对数值型特征可用）\\n         most_frequent,用众数填补（对数值型和字符型特征都可用）\\n         constant,表示请参考参数fill_value中的值（对数值型和字符型特征都可用）\\nfill_vale:当参数strategy为contant的时候可用，可输入字符串或数字表示要填充的值，常用0\\ncopy:默认True，将创建特征矩阵的副本，反之则会将缺失值填补到原来的特征矩阵中去\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''四个重要参数：\n",
    "missing_values:告诉SimpleImputer,数据中的缺失值长什么样，默认np.nan \n",
    "strategy:我们填补缺失值的策略，默认均值。\n",
    "         mean,使用均值（仅对数值型特征可用）\n",
    "         median,使用中值填补（仅对数值型特征可用）\n",
    "         most_frequent,用众数填补（对数值型和字符型特征都可用）\n",
    "         constant,表示请参考参数fill_value中的值（对数值型和字符型特征都可用）\n",
    "fill_vale:当参数strategy为contant的时候可用，可输入字符串或数字表示要填充的值，常用0\n",
    "copy:默认True，将创建特征矩阵的副本，反之则会将缺失值填补到原来的特征矩阵中去\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         714 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    889 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.],\n",
       "       [38.],\n",
       "       [26.],\n",
       "       [35.],\n",
       "       [35.],\n",
       "       [nan],\n",
       "       [54.],\n",
       "       [ 2.],\n",
       "       [27.],\n",
       "       [14.],\n",
       "       [ 4.],\n",
       "       [58.],\n",
       "       [20.],\n",
       "       [39.],\n",
       "       [14.],\n",
       "       [55.],\n",
       "       [ 2.],\n",
       "       [nan],\n",
       "       [31.],\n",
       "       [nan]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Age = data.loc[:,\"Age\"].values.reshape(-1,1)            #sklearn当中特征矩阵必须是二维\n",
    "Age[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.        ]\n",
      " [38.        ]\n",
      " [26.        ]\n",
      " [35.        ]\n",
      " [35.        ]\n",
      " [29.69911765]\n",
      " [54.        ]\n",
      " [ 2.        ]\n",
      " [27.        ]\n",
      " [14.        ]\n",
      " [ 4.        ]\n",
      " [58.        ]\n",
      " [20.        ]\n",
      " [39.        ]\n",
      " [14.        ]\n",
      " [55.        ]\n",
      " [ 2.        ]\n",
      " [29.69911765]\n",
      " [31.        ]\n",
      " [29.69911765]]\n",
      "[[22.]\n",
      " [38.]\n",
      " [26.]\n",
      " [35.]\n",
      " [35.]\n",
      " [28.]\n",
      " [54.]\n",
      " [ 2.]\n",
      " [27.]\n",
      " [14.]\n",
      " [ 4.]\n",
      " [58.]\n",
      " [20.]\n",
      " [39.]\n",
      " [14.]\n",
      " [55.]\n",
      " [ 2.]\n",
      " [28.]\n",
      " [31.]\n",
      " [28.]]\n",
      "[[22.]\n",
      " [38.]\n",
      " [26.]\n",
      " [35.]\n",
      " [35.]\n",
      " [ 0.]\n",
      " [54.]\n",
      " [ 2.]\n",
      " [27.]\n",
      " [14.]\n",
      " [ 4.]\n",
      " [58.]\n",
      " [20.]\n",
      " [39.]\n",
      " [14.]\n",
      " [55.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [31.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer()#实例化，默认均值填补\n",
    "imp_median = SimpleImputer(strategy=\"median\")           #用中位数填补\n",
    "imp_0 = SimpleImputer(strategy=\"constant\",fill_value=0) #用0填补\n",
    "imp_mean = imp_mean.fit_transform(Age)                  #fit_transform一步完成调取结果\n",
    "imp_median = imp_median.fit_transform(Age)\n",
    "imp_0 = imp_0.fit_transform(Age)\n",
    "print(imp_mean[:20])\n",
    "print(imp_median[:20])\n",
    "print(imp_0[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         891 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    889 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#在这里我们使用中位数填补Age\n",
    "data.loc[:,\"Age\"] = imp_median\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         891 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    891 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#使用众数填补Embarked\n",
    "Embarked = data.loc[:,\"Embarked\"].values.reshape(-1,1)\n",
    "\n",
    "imp_mode = SimpleImputer(strategy='most_frequent')\n",
    "data.loc[:,'Embarked'] = imp_mode.fit_transform(Embarked)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理分类型数据：编码和哑变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### preprocessing.LabelEncoder 标签专用，能够将分类转换为分类数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:[0 2 2 2 0 0 0 0 2 2 1 2 0 0 0 1 0 2 0 2 1 2 2 2 0 1 0 0 2 0 0 2 2 0 0 0 2\n",
      " 0 0 2 0 0 0 1 2 0 0 2 0 0 0 0 2 2 0 2 2 0 2 0 0 2 0 0 0 2 2 0 2 0 0 0 0 0\n",
      " 2 1 0 1 2 2 0 2 2 0 2 2 0 0 2 0 0 0 0 0 0 0 1 2 2 0 0 0 0 0 0 0 2 2 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 2 2 0 1 0 0 2 0 0 2 0 0 0 1 1 2 0 0 0 2 0\n",
      " 0 1 0 1 1 0 0 0 2 0 0 0 0 2 0 0 0 2 2 0 0 0 1 0 2 0 0 0 1 0 0 0 0 0 0 1 2\n",
      " 0 2 2 0 0 2 0 2 1 2 2 0 0 1 0 0 0 0 0 2 0 0 2 2 2 1 2 1 0 0 2 2 0 2 0 2 0\n",
      " 0 0 2 0 2 0 0 0 2 1 0 2 0 0 0 2 0 0 0 2 0 0 0 0 0 2 2 0 0 0 0 1 0 2 2 2 2\n",
      " 2 0 2 0 1 0 0 1 2 2 1 0 2 2 0 2 2 0 0 1 1 0 0 0 2 0 0 2 0 2 2 2 2 0 0 0 0\n",
      " 0 0 2 2 2 2 1 2 0 2 2 2 0 2 2 2 0 0 0 2 2 1 2 2 0 1 2 2 0 2 0 1 2 2 2 0 1\n",
      " 0 2 0 0 2 1 0 2 2 0 0 0 2 2 2 2 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 2 2 2 1\n",
      " 2 0 0 0 0 2 2 0 0 0 2 2 0 2 0 0 0 2 0 2 2 2 0 2 2 0 0 0 0 2 2 1 0 0 0 1 0\n",
      " 2 0 0 0 0 2 0 2 0 1 2 0 0 0 0 0 0 0 0 2 2 0 2 2 2 2 0 0 2 0 2 0 0 2 0 0 2\n",
      " 2 2 2 2 2 2 0 0 0 2 1 2 0 2 2 0 2 1 0 0 0 0 0 0 0 1 1 0 2 2 0 0 1 0 0 2 0\n",
      " 0 0 2 2 1 2 0 0 1 0 0 1 0 0 0 2 1 0 0 0 0 0 0 2 1 2 2 1 2 2 0 2 2 1 0 2 0\n",
      " 2 0 2 0 0 2 0 0 2 0 0 0 2 0 1 2 0 2 0 2 0 2 2 0 1 2 0 0 2 2 1 2 2 0 0 2 2\n",
      " 0 2 0 2 2 0 0 0 0 1 0 1 0 1 1 2 2 1 2 0 0 2 2 0 2 2 2 0 0 0 2 0 2 1 0 0 2\n",
      " 0 0 0 0 2 0 0 2 2 0 0 0 2 0 1 2 2 1 0 0 2 0 0 1 0 0 2 0 0 2 2 0 0 0 1 2 1\n",
      " 0 1 0 2 0 0 2 0 0 0 0 0 2 0 2 2 2 1 2 0 2 0 2 0 2 0 0 0 0 0 0 1 0 0 0 2 0\n",
      " 0 0 0 2 2 0 0 2 0 0 0 2 0 2 0 2 0 0 0 0 0 0 0 2 2 2 2 1 1 1 1 2 0 0 2 2 0\n",
      " 0 0 0 1 2 2 2 2 0 1 0 1 1 2 1 0 0 2 0 0 0 2 0 2 2 1 1 2 0 1 0 0 0 0 2 0 0\n",
      " 2 0 2 0 2 0 0 2 0 0 2 2 1 0 2 2 0 0 0 2 0 0 2 2 0 2 0 0 0 0 0 1 0 0 1 1 0\n",
      " 2 0 2 2 2 0 0 0 0 2 0 2 0 0 0 0 0 0 0 2 2 0 0 0 2 2 2 2 0 0 0 0 2 0 1 0 1\n",
      " 0 0 0 0 0 0 2 2 0 2 0 0 0 2 2 2 2 2 0 0 0 2 0 0 2 2 0 0 2 0 0 1 0 0 0 1 1\n",
      " 0 1 2 0 2 2 2 2 0 0 0 2 0 1 1 1 0 0 2 0 1 0 0 2 2 0 0 0 2 2 0 0 1 0 0 0 2\n",
      " 0 1 0]\n",
      "le.classes_:['No' 'Unknown' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = data.iloc[:,-1] #要输入的是标签，不是特征矩阵，所以允许一维\n",
    "\n",
    "le = LabelEncoder() #实例化\n",
    "le = le.fit(y) #导入数据\n",
    "label = le.transform(y) # transform接口调取结果\n",
    "\n",
    "print(\"label:{}\".format(label)) #查看获取的结果label\n",
    "print(\"le.classes_:{}\".format(le.classes_)) #属性classes_查看标签中究竟有多少类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0, 0, 1, 0, 2, 0, 2, 1, 2,\n",
       "       2, 2, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1,\n",
       "       2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2,\n",
       "       2, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 1, 0,\n",
       "       0, 2, 0, 0, 2, 0, 0, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 1, 0, 0, 2, 2, 0, 2, 0,\n",
       "       2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 2, 0, 2, 0, 1,\n",
       "       0, 0, 1, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0,\n",
       "       2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2,\n",
       "       0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2,\n",
       "       2, 0, 1, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 0, 0, 0,\n",
       "       0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0,\n",
       "       0, 0, 0, 2, 2, 1, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 0,\n",
       "       2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 1, 2, 0, 2, 2, 0, 2, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2,\n",
       "       2, 1, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1,\n",
       "       2, 2, 1, 2, 2, 0, 2, 2, 1, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0,\n",
       "       0, 0, 2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 0, 2, 2, 1, 2,\n",
       "       2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2,\n",
       "       1, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 1, 2, 2, 1, 0, 0, 2, 0, 0, 1,\n",
       "       0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 1, 2, 1, 0, 1, 0, 2, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 2, 0, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 2, 2, 0, 0,\n",
       "       0, 0, 1, 2, 2, 2, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "       2, 2, 1, 1, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2,\n",
       "       0, 0, 2, 2, 1, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2,\n",
       "       0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 2, 2, 2,\n",
       "       2, 0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2,\n",
       "       2, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit_transform(y) #使用fit_transform一步到位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Unknown', 'Yes', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Unknown', 'Yes', 'Yes', 'Yes', 'No', 'Unknown', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Unknown', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Unknown', 'No',\n",
       "       'Unknown', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Unknown', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Unknown', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'Unknown', 'Unknown', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'Unknown', 'No', 'Unknown', 'Unknown',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No',\n",
       "       'No', 'No', 'Unknown', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Unknown', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Unknown', 'Yes', 'Yes', 'No', 'No', 'Unknown', 'No', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'Unknown', 'Yes', 'Unknown', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'Unknown', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'No', 'Unknown', 'No', 'No', 'Unknown',\n",
       "       'Yes', 'Yes', 'Unknown', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'Unknown', 'Unknown', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'Yes', 'Unknown', 'Yes', 'Yes', 'No', 'Unknown',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'No', 'Unknown', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'Unknown', 'No', 'Yes', 'No', 'No', 'Yes', 'Unknown', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Unknown',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'Unknown', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Unknown', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'Yes', 'Unknown', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'No', 'Yes', 'Unknown', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Unknown', 'Unknown', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Unknown', 'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'Unknown',\n",
       "       'No', 'No', 'No', 'Yes', 'Unknown', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'Unknown', 'Yes', 'Yes', 'Unknown', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'Unknown', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'Unknown', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Unknown', 'Yes', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Unknown', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Unknown', 'No',\n",
       "       'Unknown', 'No', 'Unknown', 'Unknown', 'Yes', 'Yes', 'Unknown',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'Yes', 'Unknown', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'Yes', 'Yes', 'Unknown', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'Unknown', 'Yes', 'Unknown', 'No',\n",
       "       'Unknown', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes', 'No',\n",
       "       'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Unknown', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'Yes', 'Yes', 'Unknown', 'Unknown', 'Unknown',\n",
       "       'Unknown', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'Unknown', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Unknown', 'No',\n",
       "       'Unknown', 'Unknown', 'Yes', 'Unknown', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Unknown', 'Unknown', 'Yes',\n",
       "       'No', 'Unknown', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'Yes', 'Unknown', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Unknown', 'No', 'No', 'Unknown', 'Unknown', 'No', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'No', 'Unknown', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Unknown', 'No',\n",
       "       'No', 'No', 'Unknown', 'Unknown', 'No', 'Unknown', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'Unknown', 'Unknown', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'No'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(label) #使用inverse_transform可以逆转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         2\n",
       "2  26.0  female        S         2\n",
       "3  35.0  female        S         2\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,-1] = label #让标签等于我们运行出来的结果\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### preprocessing.OrdinalEncoder：特征专用，能够将分类特征转换为分类数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         2\n",
       "2  26.0  female        S         2\n",
       "3  35.0  female        S         2\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#接口categories_对应LabelEncoder的接口classes_，一模一样的功能\n",
    "\n",
    "data_ = data.copy()\n",
    "data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object), array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrdinalEncoder().fit(data_.iloc[:,1:-1]).categories_ # [:,1:-1]所有行  第一列到最后一列 .categories_类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.iloc[:,1:-1] = OrdinalEncoder().fit_transform(data_.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  Embarked  Survived\n",
       "0  22.0  1.0       2.0         0\n",
       "1  38.0  0.0       0.0         2\n",
       "2  26.0  0.0       2.0         2\n",
       "3  35.0  0.0       2.0         2\n",
       "4  35.0  1.0       2.0         0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### preprocessing.OneHotEncoder：独热编码，创建哑变量\n",
    "我们刚才已经用OrdinalEncoder把分类变量Sex和Embarked都转换成数字对应的类别了。在舱门Embarked这一列中，我们使用[0,1,2]代表了三个不同的舱门，然而这种转换是正确的吗？我们来思考三种不同性质的分类数据：1）舱门（S，C，Q）三种取值S，C，Q是相互独立的，彼此之间完全没有联系，表达的是S≠C≠Q的概念。这是名义变量。2）学历（小学，初中，高中）三种取值不是完全独立的，我们可以明显看出，在性质上可以有高中>初中>小学这样的联系，学历有高低，但是学历取值之间却不是可以计算的，我们不能说小学 + 某个取值 = 初中。这是有序变量。3）体重（>45kg，>90kg，>135kg）各个取值之间有联系，且是可以互相计算的，比如120kg - 45kg = 90kg，分类之间可以通过数学计算互相转换。这是有距变量。然而在对特征进行编码的时候，这三种分类数据都会被我们转换为[0,1,2]，这三个数字在算法看来，是连续且可以计算的，这三个数字相互不等，有大小，并且有着可以相加相乘的联系。所以算法会把舱门，学历这样的分类特征，都误会成是体重这样的分类特征。这是说，我们把分类转换成数字的时候，忽略了数字中自带的数学性质，所以给算法传达了一些不准确的信息，而这会影响我们的建模."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = data.iloc[:,1:-1] #所有的行和第一列到最后一列\n",
    "\n",
    "enc = OneHotEncoder(categories='auto').fit(X) #自动模式\n",
    "result = enc.transform(X).toarray() #transform是一个稀疏矩阵，转化为array格式\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步\n",
    "OneHotEncoder(categories='auto').fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>female</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>female</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>female</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  1\n",
       "0      male  S\n",
       "1    female  C\n",
       "2    female  S\n",
       "3    female  S\n",
       "4      male  S\n",
       "5      male  Q\n",
       "6      male  S\n",
       "7      male  S\n",
       "8    female  S\n",
       "9    female  C\n",
       "10   female  S\n",
       "11   female  S\n",
       "12     male  S\n",
       "13     male  S\n",
       "14   female  S\n",
       "15   female  S\n",
       "16     male  Q\n",
       "17     male  S\n",
       "18   female  S\n",
       "19   female  C\n",
       "20     male  S\n",
       "21     male  S\n",
       "22   female  Q\n",
       "23     male  S\n",
       "24   female  S\n",
       "25   female  S\n",
       "26     male  C\n",
       "27     male  S\n",
       "28   female  Q\n",
       "29     male  S\n",
       "..      ... ..\n",
       "861    male  S\n",
       "862  female  S\n",
       "863  female  S\n",
       "864    male  S\n",
       "865  female  S\n",
       "866  female  C\n",
       "867    male  S\n",
       "868    male  S\n",
       "869    male  S\n",
       "870    male  S\n",
       "871  female  S\n",
       "872    male  S\n",
       "873    male  S\n",
       "874  female  C\n",
       "875  female  C\n",
       "876    male  S\n",
       "877    male  S\n",
       "878    male  S\n",
       "879  female  C\n",
       "880  female  S\n",
       "881    male  S\n",
       "882  female  S\n",
       "883    male  S\n",
       "884    male  S\n",
       "885  female  Q\n",
       "886    male  S\n",
       "887  female  S\n",
       "888  female  S\n",
       "889    male  C\n",
       "890    male  Q\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 依然可以还原\n",
    "pd.DataFrame(enc.inverse_transform(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_female', 'x0_male', 'x1_C', 'x1_Q', 'x1_S'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names()  #查看所有的属性名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived    0    1    2    3    4\n",
       "0  22.0    male        S         0  0.0  1.0  0.0  0.0  1.0\n",
       "1  38.0  female        C         2  1.0  0.0  1.0  0.0  0.0\n",
       "2  26.0  female        S         2  1.0  0.0  0.0  0.0  1.0\n",
       "3  35.0  female        S         2  1.0  0.0  0.0  0.0  1.0\n",
       "4  35.0    male        S         0  0.0  1.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#axis=1,表示跨行进行合并，也就是将量表左右相连，如果是axis=0，就是将量表上下相连\n",
    "newdata = pd.concat([data,pd.DataFrame(result)],axis = 1)\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Survived  Female  Male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0  22.0         0     0.0   1.0         0.0         0.0         1.0\n",
       "1  38.0         2     1.0   0.0         1.0         0.0         0.0\n",
       "2  26.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "3  35.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "4  35.0         0     0.0   1.0         0.0         0.0         1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.drop(['Sex','Embarked'],axis=1,inplace = True) #将Sex和Embarked整列删除\n",
    "newdata.columns = ['Age','Survived','Female','Male','Embarked_C','Embarked_Q','Embarked_S'] #跟换列名\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理连续型特征，二值化与分段\n",
    "##### sklearn.preprocessing.Binarizer\n",
    "根据阈值将数据二值化（将特征值设置为0或1），用于处理连续型变量。大于阈值的值映射为1，而小于或等于阈值的值映射\n",
    "为0。二值化是对文本计数数据的常见操作，分析人员可以决定仅考虑某种现象的存在与否。它还可以用作考虑布尔随机变量\n",
    "的估计器的预处理步骤（例如，使用贝叶斯设置中的伯努利分布建模）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将年龄二值化\n",
    "data_2 = data.copy()\n",
    "from sklearn.preprocessing import Binarizer\n",
    "X = data_2.iloc[:,0].values.reshape(-1,1)  #类为特征专用，所以不能使用一维数组\n",
    "transformer = Binarizer(threshold=30).fit_transform(X) #大于30的1 小于等于30的为0\n",
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### preprocessing.KBinsDiscretizer\n",
    "这是将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。总共包含三个重要参数\n",
    "###### n_bins 每个特征中分箱的个数，默认5，一次会被运用到所有导入的特征\n",
    "###### encode 编码的方式，默认onehot\n",
    "\"onehot\"：做哑变量，之后返回一个稀疏矩阵，每一列是一个特征中的一个类别，含有该类别的样本表示为1，不含的表示为0 “ordinal”：每个特征的每个箱都被编码为一个整数，返回每一列是一个特征，每个特征下含有不同整数编码的箱的矩阵\"onehot-dense\"：做哑变量，之后返回一个密集数组。\n",
    "###### strategy 用来定义箱宽的方式，默认‘quantile’\n",
    "'uniform':表示等宽分箱，即每个特征中的每个箱的最大值之间的差为(特征.max() - 特征.min())/(n_bins) \n",
    "\"quantile\"：表示等位分箱，即每个特征中的每个箱内的样本数量都相同\"kmeans\"：表示按聚类分箱，每个箱中的值到最近的一维k均值聚类的簇心得距离都相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0, 2.0}\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "x = data.iloc[:,0].values.reshape(-1,1)\n",
    "est = KBinsDiscretizer(n_bins=3,encode='ordinal',strategy='uniform')  #等宽分箱\n",
    "est.fit_transform(x)\n",
    "\n",
    "#查看转换后分的箱：变成了一列中的三箱\n",
    "print(set(est.fit_transform(X).ravel()))\n",
    "\n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n",
    "#查看转换后分的箱：变成了哑变量\n",
    "print(est.fit_transform(X).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 我们有四种方法可以用来选择特征：过滤法，嵌入法，包装法，和降维算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入数据，使用数据识别数据\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r'digit recognizor.csv')\n",
    "\n",
    "X = data.iloc[:,1:] #选定所有行，第二列开始到结束\n",
    "y = data.iloc[:,0] #选定所有行，第一列\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Filter过滤法\n",
    "过滤方法通常用作预处理步骤，特征选择完全独立于任何机器学习算法。它是根据各种统计检验中的分数以及相关性的各项指标来选择特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方差过滤\n",
    "###### VarianceThreshold\n",
    "这是通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征上基本没有差异，可能特征中的大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有什么作用。所以无论接下来的特征工程要做什么，都要优先消除方差为0的特征。VarianceThreshold有重要参数threshold，表示方差的阈值，表示舍弃所有方差小于threshold的特征，不填默认为0，即删除所有的记录都相同的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 708)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold() #实例化，不填参数默认方差为0\n",
    "X_var0 = selector.fit_transform(X) #获取删除不合格特征之后的新特征矩阵\n",
    "\n",
    "#也可以直接写成X=VarianceThreshold().fit_transform(X)\n",
    "X_var0.shape\n",
    "'''可以看到我们已经删除了方差为0的特征（特征中所有的数都一样），但还剩708个特征，明显需要进一步的特征选择。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_var:[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 3.22760590e-01 2.64689018e+00 1.11085714e+00 1.92857143e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 6.09523810e-03 5.41186213e-02 1.28065733e+00 5.33793150e+00\n",
      " 9.74592647e+00 1.06219147e+01 2.49289953e+01 3.37671294e+01\n",
      " 3.59425660e+01 3.49309575e+01 3.62943342e+01 3.27911079e+01\n",
      " 3.04237672e+01 2.95547817e+01 2.00568398e+01 1.19545659e+01\n",
      " 8.60419724e+00 2.55465685e+00 1.60530842e+00 9.29377602e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.75238095e-02 2.00238095e-02\n",
      " 8.38442376e-01 6.23481035e-01 9.48446647e+00 2.93530906e+01\n",
      " 5.67872968e+01 1.00230634e+02 1.65873698e+02 2.52738939e+02\n",
      " 3.76018084e+02 5.14426094e+02 6.50102357e+02 7.26608631e+02\n",
      " 7.20549617e+02 6.49594181e+02 5.18814455e+02 3.94092376e+02\n",
      " 2.35038093e+02 1.14843923e+02 5.61521180e+01 1.70331842e+01\n",
      " 6.48083740e+00 1.08821717e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 4.76236337e-01 2.75489198e-01\n",
      " 1.29297595e+00 1.26446724e+01 4.28153306e+01 9.43924926e+01\n",
      " 2.15866693e+02 4.40079141e+02 7.26679321e+02 1.10776068e+03\n",
      " 1.49073923e+03 1.93993499e+03 2.31552090e+03 2.59022407e+03\n",
      " 2.49637882e+03 2.22627799e+03 1.80800104e+03 1.31417708e+03\n",
      " 7.95887557e+02 4.41320506e+02 1.99165391e+02 7.95865424e+01\n",
      " 3.10264989e+01 2.26837146e+00 3.48595238e-01 0.00000000e+00\n",
      " 0.00000000e+00 3.43809524e-02 1.15447633e-01 1.25289059e+00\n",
      " 1.15530325e+01 6.16749834e+01 1.71059884e+02 4.37266473e+02\n",
      " 9.14503323e+02 1.61733281e+03 2.58238559e+03 3.73319320e+03\n",
      " 4.97101576e+03 6.18285701e+03 7.12176198e+03 7.61902605e+03\n",
      " 7.35140128e+03 6.59732933e+03 5.42159265e+03 4.14622275e+03\n",
      " 2.74210919e+03 1.60716526e+03 8.30092375e+02 3.85524893e+02\n",
      " 1.44471061e+02 2.98361218e+01 5.45472846e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.16499590e-01 5.19710545e+00\n",
      " 6.12264995e+01 2.53650903e+02 6.51218510e+02 1.32512948e+03\n",
      " 2.39625599e+03 3.90432573e+03 5.65248822e+03 7.50750831e+03\n",
      " 9.28013155e+03 1.07098605e+04 1.15505424e+04 1.18353399e+04\n",
      " 1.16728383e+04 1.10553420e+04 9.77051209e+03 8.00603359e+03\n",
      " 5.90601149e+03 3.83759619e+03 2.22900745e+03 1.15756773e+03\n",
      " 5.07963705e+02 1.22007799e+02 1.78286793e+01 7.71428571e-03\n",
      " 0.00000000e+00 3.80952381e-04 2.37199928e+00 3.95713081e+01\n",
      " 2.07427935e+02 6.06480056e+02 1.37944393e+03 2.64652318e+03\n",
      " 4.39063213e+03 6.55335113e+03 8.64850053e+03 1.03924767e+04\n",
      " 1.16602029e+04 1.23720092e+04 1.25944602e+04 1.26223718e+04\n",
      " 1.26261428e+04 1.25617677e+04 1.20570623e+04 1.07029270e+04\n",
      " 8.66359114e+03 6.04366459e+03 3.77715738e+03 2.05026195e+03\n",
      " 9.47173606e+02 3.04430342e+02 5.49548377e+01 3.50648111e+00\n",
      " 0.00000000e+00 1.47595606e+00 1.73365714e+01 1.03708159e+02\n",
      " 4.49220215e+02 1.11598051e+03 2.31261700e+03 4.05981199e+03\n",
      " 6.27112094e+03 8.61258120e+03 1.04088978e+04 1.15863594e+04\n",
      " 1.20861191e+04 1.22313676e+04 1.22256615e+04 1.21230025e+04\n",
      " 1.21304108e+04 1.22345097e+04 1.22810693e+04 1.17587829e+04\n",
      " 1.01382911e+04 7.63237251e+03 4.91736987e+03 2.72324144e+03\n",
      " 1.22087326e+03 4.16952121e+02 7.84619988e+01 2.69471891e+00\n",
      " 6.68809524e-02 1.14742637e+01 7.06094700e+01 2.58579123e+02\n",
      " 7.58812237e+02 1.66236697e+03 3.16372296e+03 5.28061009e+03\n",
      " 7.80859675e+03 1.00912727e+04 1.16171690e+04 1.22797788e+04\n",
      " 1.23833077e+04 1.24581779e+04 1.23866060e+04 1.23021558e+04\n",
      " 1.22796752e+04 1.23185424e+04 1.24370140e+04 1.21441547e+04\n",
      " 1.08800641e+04 8.45510124e+03 5.53590659e+03 2.92299426e+03\n",
      " 1.27293575e+03 4.39632397e+02 7.77464211e+01 2.35152706e+00\n",
      " 1.41387108e+00 1.83873300e+01 1.01219976e+02 3.59094119e+02\n",
      " 9.16376867e+02 1.90547923e+03 3.64144404e+03 6.06890402e+03\n",
      " 8.86696591e+03 1.10299773e+04 1.21997003e+04 1.24677668e+04\n",
      " 1.23878202e+04 1.20816759e+04 1.18414911e+04 1.18243379e+04\n",
      " 1.19196049e+04 1.22058487e+04 1.24040782e+04 1.21013351e+04\n",
      " 1.08905421e+04 8.53288188e+03 5.50599673e+03 2.77180472e+03\n",
      " 1.06085951e+03 3.12689774e+02 5.19949129e+01 5.02228364e+00\n",
      " 3.12121001e+00 1.92336286e+01 1.00196288e+02 3.33760276e+02\n",
      " 8.42723536e+02 1.87713749e+03 3.80614513e+03 6.46513903e+03\n",
      " 9.41022768e+03 1.14543460e+04 1.22494028e+04 1.22551059e+04\n",
      " 1.15972630e+04 1.07756156e+04 1.05723907e+04 1.10540147e+04\n",
      " 1.14904415e+04 1.20641837e+04 1.22340857e+04 1.19219747e+04\n",
      " 1.04672465e+04 8.02282693e+03 5.11996418e+03 2.49340573e+03\n",
      " 8.29185839e+02 2.02728469e+02 3.65252982e+01 4.73545802e+00\n",
      " 6.54689762e-01 1.10762921e+01 8.21810900e+01 2.45993138e+02\n",
      " 6.88037918e+02 1.77097595e+03 3.89510214e+03 6.82414020e+03\n",
      " 9.88524752e+03 1.16866740e+04 1.22052249e+04 1.18503310e+04\n",
      " 1.08057141e+04 1.00029368e+04 1.05613005e+04 1.13459087e+04\n",
      " 1.16813954e+04 1.21153444e+04 1.22013911e+04 1.16257849e+04\n",
      " 9.77524122e+03 7.24039730e+03 4.72965127e+03 2.39611574e+03\n",
      " 7.37971166e+02 1.05994299e+02 2.09059137e+01 7.86044778e-01\n",
      " 6.32595238e-01 6.32770971e+00 4.96597411e+01 1.73335928e+02\n",
      " 5.64355135e+02 1.79246896e+03 4.19852946e+03 7.42330328e+03\n",
      " 1.03680620e+04 1.19241275e+04 1.22167302e+04 1.17312041e+04\n",
      " 1.08331969e+04 1.06956425e+04 1.18765965e+04 1.23125550e+04\n",
      " 1.21036991e+04 1.23648277e+04 1.23532159e+04 1.12659827e+04\n",
      " 9.01309194e+03 6.65304923e+03 4.53230600e+03 2.53236771e+03\n",
      " 8.13317532e+02 7.57360821e+01 1.22663918e+01 9.49856083e-01\n",
      " 2.43809524e-02 2.05312854e+00 2.37737153e+01 1.15295050e+02\n",
      " 5.23151198e+02 2.00356402e+03 4.71208413e+03 8.02210576e+03\n",
      " 1.07142826e+04 1.19844734e+04 1.21443066e+04 1.17352672e+04\n",
      " 1.13501890e+04 1.18058310e+04 1.29305253e+04 1.24664835e+04\n",
      " 1.21090771e+04 1.25723716e+04 1.24760936e+04 1.09595385e+04\n",
      " 8.66572810e+03 6.56048630e+03 4.59945505e+03 2.74090145e+03\n",
      " 9.79975029e+02 1.02467830e+02 1.16955902e+01 2.92035599e+00\n",
      " 0.00000000e+00 8.53042930e-01 8.80331299e+00 7.52414185e+01\n",
      " 5.33884018e+02 2.30333924e+03 5.22384299e+03 8.41596660e+03\n",
      " 1.08537671e+04 1.19270178e+04 1.19856397e+04 1.17039418e+04\n",
      " 1.16715555e+04 1.24445986e+04 1.29618550e+04 1.20230391e+04\n",
      " 1.20377425e+04 1.26434659e+04 1.24012680e+04 1.08759560e+04\n",
      " 8.87523588e+03 6.85569402e+03 4.84378377e+03 2.91796192e+03\n",
      " 1.10844668e+03 1.39672375e+02 8.86639995e+00 7.94981734e-02\n",
      " 0.00000000e+00 0.00000000e+00 4.63950502e+00 8.33393904e+01\n",
      " 6.29744755e+02 2.69185746e+03 5.62185375e+03 8.53435292e+03\n",
      " 1.06354679e+04 1.16397177e+04 1.17410232e+04 1.17248709e+04\n",
      " 1.20446633e+04 1.27114555e+04 1.27125078e+04 1.20008852e+04\n",
      " 1.24098689e+04 1.26745406e+04 1.20741286e+04 1.08898533e+04\n",
      " 9.21323231e+03 7.22598679e+03 5.04689745e+03 2.90913735e+03\n",
      " 1.12277645e+03 1.91078386e+02 2.57469149e+01 1.29179123e+00\n",
      " 0.00000000e+00 7.69744852e-02 1.03197870e+01 1.11053766e+02\n",
      " 8.11564748e+02 3.07386387e+03 5.91065656e+03 8.36008213e+03\n",
      " 1.01408287e+04 1.10632136e+04 1.12910607e+04 1.14976813e+04\n",
      " 1.20735231e+04 1.27502876e+04 1.26987222e+04 1.23901805e+04\n",
      " 1.26170244e+04 1.23916950e+04 1.17483338e+04 1.09217037e+04\n",
      " 9.48760960e+03 7.35171522e+03 5.01095743e+03 2.72992609e+03\n",
      " 1.04916705e+03 2.25941630e+02 3.05993271e+01 2.87316363e+00\n",
      " 0.00000000e+00 2.28039253e-01 1.74352649e+01 1.69998742e+02\n",
      " 1.10767541e+03 3.43926495e+03 6.05208363e+03 8.08344097e+03\n",
      " 9.50906305e+03 1.03073030e+04 1.06715518e+04 1.10973680e+04\n",
      " 1.17642567e+04 1.22940460e+04 1.25222837e+04 1.24838281e+04\n",
      " 1.23538616e+04 1.20985659e+04 1.17177753e+04 1.10570877e+04\n",
      " 9.47381642e+03 7.19094489e+03 4.63491474e+03 2.42432309e+03\n",
      " 9.17534777e+02 2.34119338e+02 3.27687618e+01 1.59861539e+00\n",
      " 1.47639388e-01 4.47934602e-01 2.76028871e+01 2.71942488e+02\n",
      " 1.45371251e+03 3.83133451e+03 6.28631187e+03 8.14612790e+03\n",
      " 9.30917203e+03 1.00179199e+04 1.05639229e+04 1.09925571e+04\n",
      " 1.13187529e+04 1.19116163e+04 1.23480093e+04 1.23440430e+04\n",
      " 1.21692394e+04 1.21290528e+04 1.19460348e+04 1.11011974e+04\n",
      " 9.19667530e+03 6.71976236e+03 4.18683656e+03 2.12415117e+03\n",
      " 8.18965786e+02 2.22857925e+02 2.54140760e+01 1.36995713e+00\n",
      " 0.00000000e+00 1.81578450e+00 4.96345920e+01 3.80903626e+02\n",
      " 1.68403918e+03 4.10905800e+03 6.66129020e+03 8.56235623e+03\n",
      " 9.76878976e+03 1.05714566e+04 1.11195093e+04 1.14535438e+04\n",
      " 1.17907581e+04 1.21204054e+04 1.24479360e+04 1.23900112e+04\n",
      " 1.22489975e+04 1.23606302e+04 1.19785927e+04 1.06491638e+04\n",
      " 8.49640625e+03 5.95805507e+03 3.53263357e+03 1.70287256e+03\n",
      " 6.43673157e+02 1.79133677e+02 2.84028991e+01 6.28175963e-01\n",
      " 0.00000000e+00 1.23625493e+00 5.65580767e+01 4.36617659e+02\n",
      " 1.67611596e+03 3.91825583e+03 6.61848502e+03 8.93197399e+03\n",
      " 1.05084494e+04 1.14328933e+04 1.19110401e+04 1.21686631e+04\n",
      " 1.23576844e+04 1.24269771e+04 1.24145723e+04 1.24011494e+04\n",
      " 1.23905027e+04 1.22793811e+04 1.14389559e+04 9.61909799e+03\n",
      " 7.11272858e+03 4.61189510e+03 2.55069845e+03 1.22448673e+03\n",
      " 4.85654757e+02 1.30709778e+02 1.54997227e+01 5.95238095e-02\n",
      " 2.43809524e-02 5.50986923e-01 4.58334020e+01 3.50464999e+02\n",
      " 1.27200240e+03 3.19694301e+03 5.84711073e+03 8.57024623e+03\n",
      " 1.06775424e+04 1.19000918e+04 1.23555360e+04 1.24402093e+04\n",
      " 1.23586522e+04 1.21992581e+04 1.22280936e+04 1.23162507e+04\n",
      " 1.22510127e+04 1.16314635e+04 1.00849238e+04 7.71018098e+03\n",
      " 5.16732671e+03 2.99318809e+03 1.58471510e+03 7.70678750e+02\n",
      " 2.90603130e+02 7.36919311e+01 9.81920114e+00 3.62142857e-02\n",
      " 2.28809524e-02 2.76185941e-03 2.81056704e+01 2.04208025e+02\n",
      " 7.29051694e+02 2.00572701e+03 4.21366647e+03 6.92346357e+03\n",
      " 9.57389827e+03 1.14603398e+04 1.24666788e+04 1.27682484e+04\n",
      " 1.26613017e+04 1.25534327e+04 1.25998206e+04 1.23927837e+04\n",
      " 1.15590439e+04 9.88953142e+03 7.53295513e+03 5.11441259e+03\n",
      " 3.05547189e+03 1.66092585e+03 8.39969863e+02 3.84512312e+02\n",
      " 1.34737119e+02 2.71408189e+01 3.06857624e+00 1.23428571e-01\n",
      " 0.00000000e+00 0.00000000e+00 7.31084788e+00 7.57570670e+01\n",
      " 3.18535551e+02 8.92561149e+02 2.13007164e+03 4.15513729e+03\n",
      " 6.67943441e+03 9.08942045e+03 1.08768840e+04 1.18600478e+04\n",
      " 1.22185140e+04 1.21488922e+04 1.16761724e+04 1.06623427e+04\n",
      " 8.88180421e+03 6.72867491e+03 4.52696553e+03 2.78125867e+03\n",
      " 1.57340674e+03 7.99627345e+02 3.90776811e+02 1.74143994e+02\n",
      " 5.13083781e+01 8.53411049e+00 1.14082626e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.09874806e+00 2.12014616e+01\n",
      " 9.01086432e+01 2.89578069e+02 7.37002996e+02 1.63305438e+03\n",
      " 3.00614325e+03 4.75217719e+03 6.42418657e+03 7.68266614e+03\n",
      " 8.23705320e+03 8.21603450e+03 7.48615583e+03 6.25364040e+03\n",
      " 4.88502834e+03 3.50985901e+03 2.25424437e+03 1.40076179e+03\n",
      " 7.54457368e+02 3.85015891e+02 1.70931569e+02 7.23728862e+01\n",
      " 1.53588609e+01 3.76286683e+00 2.36378952e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.89492516e-02 3.23002085e+00\n",
      " 2.66993369e+01 8.62829380e+01 2.42567552e+02 5.74670736e+02\n",
      " 1.16062824e+03 1.85908331e+03 2.63430007e+03 3.18296192e+03\n",
      " 3.47208469e+03 3.42498298e+03 3.04423070e+03 2.59463417e+03\n",
      " 2.08583729e+03 1.54170230e+03 1.04262030e+03 6.17155891e+02\n",
      " 3.32872699e+02 1.63141373e+02 6.60019146e+01 2.49646484e+01\n",
      " 2.80197112e+00 5.64225568e-01 2.57523810e-01 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.85748256e+00 2.32008075e+01 9.24954784e+01 2.19439668e+02\n",
      " 4.27698080e+02 6.31131067e+02 9.05773738e+02 1.16529687e+03\n",
      " 1.28219277e+03 1.23351933e+03 1.09034012e+03 8.82789099e+02\n",
      " 7.26724558e+02 5.23459986e+02 3.45778063e+02 2.08353021e+02\n",
      " 1.10624593e+02 4.18520306e+01 1.58110107e+01 3.40777397e+00\n",
      " 1.94759195e-02 8.28809524e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 9.02126602e-01 5.52653803e+00 1.54785620e+01\n",
      " 2.06441456e+01 3.43017827e+01 5.21246770e+01 7.97142975e+01\n",
      " 1.00081387e+02 1.02608696e+02 1.26673478e+02 1.14405059e+02\n",
      " 8.98716430e+01 6.32064973e+01 3.98525769e+01 2.14722761e+01\n",
      " 1.07222715e+01 3.09714228e+00 3.58912164e+00 1.71614970e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "median_X_var:1352.286703180131\n",
      "X_fsvar.shape:(42000, 392)\n"
     ]
    }
   ],
   "source": [
    "'''比如说，我们希望留下一半的特征，那可以设定一个让特征总数减半的方差阈值，只要找到特征方差的中位数，\n",
    "再将这个中位数作为参数threshold的值输入就好了'''\n",
    "\n",
    "import numpy as np\n",
    "X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X)\n",
    "print('X_var:{}'.format(X.var().values))\n",
    "print('median_X_var:{}'.format(np.median(X.var().values)))\n",
    "print('X_fsvar.shape:{}'.format(X_fsvar.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN vs 随机森林在不同方差过滤效果下的对比\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "x = data.iloc[:,1:] # 选定所有行，第二列开始到结束\n",
    "y = data.iloc[:,0] # 选定所有行，第一列\n",
    "\n",
    "x_fsvar = VarianceThreshold(np.median(x.var().values)).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score:0.9658569700264943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'%%timeit\\ncross_val_score(KNN(),X,y,cv=5).mean()'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''KNN方差过滤前'''\n",
    "print('cross_val_score:{}'.format(cross_val_score(KNN(),x,y,cv=5).mean()))\n",
    "#python中的魔法命令，可以直接使用%%timeit来计算运行这个cell中的代码所需的时间\n",
    "#为了计算所需的时间，需要将这个cell中的代码运行很多次（通常是7次）后求平均值，因此运行%%timeit的时间会远远\n",
    "#超过cell中的代码单独运行的时间\n",
    "\n",
    "'''%%timeit\n",
    "cross_val_score(KNN(),X,y,cv=5).mean()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''KNN方差过滤后'''\n",
    "print('cross_val_score:{}'.format(cross_val_score(KNN(),x_fsvar,y,cv=5).mean()))\n",
    "'''%%timeit\n",
    "cross_val_score(KNN(),x_fsvar,y,cv=5).mean()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2 s ± 192 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "'''随机森林方差过滤前'''\n",
    "cross_val_score(RFC(n_estimators=10,random_state=0),x,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 过滤法的主要对象是：需要遍历特征或升维的算法们（KNN,单只决策树，SVM，神经网络，回归算法），而过滤法的主要目的是：在维持算法表现的前提下，帮助算法们降低计算成本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](1579511089(1).jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 相关性过滤\n",
    "方差挑选完毕之后，我们就要考虑下一个问题：相关性了。我们希望选出与标签相关且有意义的特征，因为这样的特征能够为我们提供大量信息。如果特征与标签无关，那只会白白浪费我们的计算内存，可能还会给模型带来噪音。在sklearn当中，我们有三种常用的方法来评判特征与标签之间的相关性：卡方，F检验，互信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 卡方检验（非负数）本质是推测两组数据之间的差异\n",
    "卡方过滤是专门针对离散型标签（即分类问题）的相关性过滤。卡方检验类feature_selection.chi2计算每个非负特征和标签之间的卡方统计量，并依照卡方统计量由高到低为特征排名。再结合feature_selection.SelectKBest这个可以输入”评分标准“来选出前K个分数最高的特征的类，我们可以借此除去最可能独立于标签，与我们分类目的无关的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest  #选分数最高k个特征的类\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#假设在这里我一直我需要300个特征\n",
    "X_fschi = SelectKBest(chi2,k=300).fit_transform(X_fsvar,y)\n",
    "X_fschi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333098667649198"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()\n",
    "'''可以看出，模型的效果降低了，这说明我们在设定k=300的时候删除了与模型相关且有效的特征，我们的k值要么设置的太小\n",
    "，要么我们需要调整k值，要么我们放弃相关性过滤。当然，如果模型的表现提升，则说明我们的相关性过滤是有效的，是过滤掉\n",
    "模型的噪声的，这时候我们就保留相关性过滤的结果'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#选取超参数k\n",
    "import matplotlib.pyplot as plt\n",
    "score = []\n",
    "for i in range(390,200,-10):\n",
    "    X_fschi = SelectKBest(chi2, k=i).fit_transform(X_fsvar, y)\n",
    "    once = cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.plot(range(390,200,-10),score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](1579516671(1).jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 945664.84392643, 1244766.05139164, 1554872.30384525,\n",
       "       1834161.78305343, 1903618.94085294, 1845226.62427198,\n",
       "       1602117.23307537,  708535.17489837,  974050.20513718,\n",
       "       1188092.19961931, 1319151.43467036, 1397847.8836796 ,\n",
       "       1433554.26798015, 1429043.15373433, 1332663.17213405,\n",
       "       1101423.25372261,  809989.56940485,  519266.71772284,\n",
       "        285681.88297156,  191589.23696468,  902883.1255264 ,\n",
       "       1237265.16042373, 1503477.73699155, 1625807.41495542,\n",
       "       1630206.90922916, 1630597.02883804, 1633456.72909664,\n",
       "       1610816.75571229, 1483382.49543886, 1256290.1574794 ,\n",
       "        951236.1617682 ,  693192.66191748,  532386.96220361,\n",
       "        504617.38933715,  575090.36046243,  501025.03733245,\n",
       "        802341.10683194, 1078344.8724406 , 1226540.98318702,\n",
       "       1269945.07968831, 1221758.57688808, 1146535.17810241,\n",
       "       1080657.20185303, 1079065.30979135, 1092222.70610032,\n",
       "       1064908.45385716, 1023327.00231067,  974163.15420165,\n",
       "        918857.12860617,  861439.52030749,  828439.23565047,\n",
       "        916454.89464771,  989713.58229958,  543695.5016699 ,\n",
       "        674691.76755044,  708113.57226969,  657819.3908855 ,\n",
       "        599159.21961671,  576483.60795847,  559848.1818137 ,\n",
       "        536985.56062372,  561457.57734769,  594428.19185935,\n",
       "        592414.89830452,  587801.84097643,  672232.60135169,\n",
       "        790511.70530618,  866573.70991777,  891422.58050934,\n",
       "        905163.15191882, 1006322.94034634,  585209.83598254,\n",
       "        699596.88963547,  705326.82387203,  641105.0929774 ,\n",
       "        632098.97938142,  725189.43548604,  853879.48154986,\n",
       "        863895.50862873,  709440.99808713,  615099.361498  ,\n",
       "        660082.35138802,  662040.13166049,  647432.43321103,\n",
       "        718070.06251003,  868119.93550552,  995128.78948214,\n",
       "        981295.46383871,  888906.74357254,  803951.63399892,\n",
       "        775220.92445238,  802661.20360682,  806753.10120013,\n",
       "        827660.8911231 , 1008184.76195542, 1212658.65697336,\n",
       "       1279652.35847441, 1071947.51866571,  712579.55021262,\n",
       "        708178.91784269,  931871.22430817,  836155.03350401,\n",
       "        781584.17446604,  883252.58134165, 1015304.18853993,\n",
       "       1153480.28062008, 1235182.10720641, 1110286.29490637,\n",
       "        762412.0228271 ,  651475.7374445 ,  659784.45490334,\n",
       "        761439.40964843,  980458.35707785, 1285689.5977369 ,\n",
       "       1412800.83270279, 1269424.03486304,  844394.53343881,\n",
       "        453037.70035635,  906205.5333485 , 1314337.38985735,\n",
       "        875502.64893107,  848574.25317153, 1088364.70535319,\n",
       "       1143964.61799576, 1231934.57606489, 1525266.11466634,\n",
       "       1624923.27849511, 1120921.66905394,  381196.04594987,\n",
       "        517011.13080559,  840830.08443577, 1249668.53527256,\n",
       "       1487299.06201808, 1440993.69232521, 1234157.54433962,\n",
       "        891091.32709079,  767327.74644144, 1767505.95851489,\n",
       "       1794612.36340341,  843649.64862696,  974860.15688277,\n",
       "       1282142.9789604 , 1121437.99502364, 1158258.4373389 ,\n",
       "       1803319.16430163, 2247538.01212782, 1715860.1009172 ,\n",
       "        308268.96279553,  670765.24199637, 1175840.18589306,\n",
       "       1569563.41213805, 1615071.70298461, 1453812.39367812,\n",
       "       1429193.59276003, 1469624.15320088, 1610038.8334007 ,\n",
       "       2381990.83018419, 1684641.44646863,  781514.82471784,\n",
       "       1136274.26981954, 1258505.95202954,  900621.20914746,\n",
       "       1033026.39393914, 2032592.30559197, 2688297.40292302,\n",
       "       2126052.31008566,  477854.94097719, 1061876.2951535 ,\n",
       "       1617721.02614334, 1859303.87013649, 1706658.49975169,\n",
       "       1442798.15960511, 1497467.99791583, 1635633.52918659,\n",
       "       1789954.0440811 , 2042036.97897042, 1243975.13567915,\n",
       "        847897.40531407, 1334491.44036763, 1146547.23628072,\n",
       "        721408.29456933, 1099901.34212844, 2234797.26301007,\n",
       "       2788060.61506624, 2097404.45292914,  770825.17396301,\n",
       "       1509971.18325275, 2008828.59327289, 2076128.28182046,\n",
       "       1775258.41727455, 1374882.05100453, 1223860.78474695,\n",
       "       1190499.55493678, 1469994.89713294, 1556218.16894472,\n",
       "        936604.6211571 , 1052799.96220046, 1487484.96092392,\n",
       "       1096221.91497984,  754081.7574313 , 1308952.47883141,\n",
       "       2269151.28497174, 2519422.4441161 , 1816912.55593098,\n",
       "       1090497.85622876, 1822356.78804369, 2192372.5304657 ,\n",
       "       2133745.04961112, 1807649.67676254, 1420349.92183107,\n",
       "       1222343.35267926, 1165504.99607627, 1500572.78318498,\n",
       "       1432663.59271325,  890862.82928644, 1274280.76943075,\n",
       "       1432072.36165076,  956997.59590817,  888742.14373383,\n",
       "       1508163.46238821, 2117988.12236915, 2054465.38907916,\n",
       "       1423918.25987689, 1286013.85962749, 1972608.25057539,\n",
       "       2179634.12755044, 1979740.23184782, 1717723.16781811,\n",
       "       1552275.10457858, 1461315.1411536 , 1494620.94971976,\n",
       "       1739520.65681857, 1442815.46046628, 1014723.34171191,\n",
       "       1363794.15539944, 1122747.63831017,  739634.35332833,\n",
       "       1067567.31929299, 1667592.5097389 , 1864455.97854722,\n",
       "       1579099.16973703,  967688.45447601, 1416605.83453248,\n",
       "       2062165.61891584, 2170645.77302745, 1901786.79198259,\n",
       "       1733725.85760386, 1753508.37671084, 1712712.42549789,\n",
       "       1733493.582237  , 1770340.59820148, 1310901.04423274,\n",
       "       1008023.90988477, 1061378.72275934,  662457.8217003 ,\n",
       "        729648.40292041, 1370253.32454603, 1741943.51510473,\n",
       "       1593454.39731162, 1172442.70958932,  671601.50140396,\n",
       "        511587.36577997, 1454955.01309647, 2126817.74478926,\n",
       "       2263953.8025206 , 2028172.33782053, 1992515.52928071,\n",
       "       2172520.74824953, 2035403.53821729, 1758624.07224114,\n",
       "       1514817.58748747, 1002116.10560135,  669379.60246184,\n",
       "        544978.32282227,  576722.03477821, 1098371.32650041,\n",
       "       1603057.05343338, 1612844.96289426, 1293107.69776289,\n",
       "        917550.19379029,  683222.7639966 ,  608782.99701169,\n",
       "       1391473.37940334, 2082151.30610954, 2298916.31712188,\n",
       "       2140360.89085296, 2070900.53848134, 2159471.16950063,\n",
       "       1981772.43302263, 1521754.51234479, 1076334.48566226,\n",
       "        610262.09016783,  351852.98340462,  461487.7601437 ,\n",
       "        878540.35993713, 1337597.14727232, 1481891.62067955,\n",
       "       1342562.57238699, 1127940.79389167,  958491.4694589 ,\n",
       "        884951.02023249,  671520.41386273, 1232265.31295026,\n",
       "       1877169.85821324, 2239501.99047448, 2199634.11766741,\n",
       "       1930471.52367226, 1666073.70450191, 1364054.30645472,\n",
       "       1000936.25390226,  656080.48075838,  389810.08772878,\n",
       "        340150.21186292,  602275.43941511,  959623.37641551,\n",
       "       1156974.48558905, 1135816.98677808, 1044294.97185606,\n",
       "        992281.03054232,  964376.78121192,  966024.75721634,\n",
       "       1491250.50567589, 1970679.86657318, 2139321.52912066,\n",
       "       1894361.40873889, 1368494.5514217 ,  829396.07488768,\n",
       "        488455.25931088,  331978.08818759,  293365.6522867 ,\n",
       "        387474.16211622,  600489.80555106,  783767.50733716,\n",
       "        831013.99296771,  768407.80393857,  738760.56078587,\n",
       "        761413.22072658,  781528.79224194,  615612.72460389,\n",
       "        975765.83585216, 1382346.6477236 , 1684701.13053512,\n",
       "       1732335.2436048 , 1492804.58962318, 1144230.23099215,\n",
       "        852589.97157847,  719215.03719448,  675891.53891187,\n",
       "        687917.5152402 ,  708292.70911948,  673810.32849758,\n",
       "        550803.45299243,  428370.7943997 ,  384587.47807058,\n",
       "        407022.00975206,  441201.32284902,  661202.45504685,\n",
       "        904150.80474087, 1098249.34334037, 1225055.2730661 ,\n",
       "       1312843.88397644, 1325774.40817926, 1236093.76813092,\n",
       "       1036608.01098297,  829620.55626671,  654964.88596563,\n",
       "        520032.72156302,  387948.22204601,  273436.39846809,\n",
       "        203015.85080751,  255471.93956392,  389884.80778864,\n",
       "        561308.92316732,  759511.94695328,  942402.80700557,\n",
       "       1044698.95132913, 1009807.32615993,  844407.23356341,\n",
       "        695110.21243546,  637789.62877943,  600582.89899187,\n",
       "        519392.9652949 ,  399631.65341907, 1006027.89058975,\n",
       "       1352052.90333271, 1647606.90721159, 1761733.4081397 ,\n",
       "       1664096.76785043, 1396834.58681766, 1159784.3628775 ,\n",
       "       1001178.01359166,  847886.28143964])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chivalue,pvalues_chi = chi2(x_fsvar,y) #卡方值和p值\n",
    "chivalue #卡方值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'可以观察到，所有特征的p值都是0，这说明对于digit recognizor这个数据集来说，方差验证已经把所有和标签无关的\\n特征都剔除了，或者这个数据集本身就不含与标签无关的特征。在这种情况下，舍弃任何一个特征，都会舍弃对模型有用的\\n信息，而使模型表现下降，因此在我们对计算速度感到满意时，我们不需要使用相关性过滤来过滤我们的数据。如果我们认\\n为运算速度太缓慢，那我们可以酌情删除一些特征，但前提是，我们必须牺牲模型的表现。接下来，我们试试看用其他的相\\n关性过滤方法验证一下我们在这个数据集上的结论。'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues_chi #p值为0 <0.05二者相关\n",
    "'''从特征工程的角度，我们希望选取卡方值很大，p值小于0.05的特征，即和标签是相关联的特征。而调用SelectKBest之\n",
    "前，我们可以直接从chi2实例化后的模型中获得各个特征所对应的卡方值和P值。'''\n",
    "'''可以观察到，所有特征的p值都是0，这说明对于digit recognizor这个数据集来说，方差验证已经把所有和标签无关的\n",
    "特征都剔除了，或者这个数据集本身就不含与标签无关的特征。在这种情况下，舍弃任何一个特征，都会舍弃对模型有用的\n",
    "信息，而使模型表现下降，因此在我们对计算速度感到满意时，我们不需要使用相关性过滤来过滤我们的数据。如果我们认\n",
    "为运算速度太缓慢，那我们可以酌情删除一些特征，但前提是，我们必须牺牲模型的表现。接下来，我们试试看用其他的相\n",
    "关性过滤方法验证一下我们在这个数据集上的结论。'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### F检验\n",
    "F检验，又称ANOVA，方差齐性检验，是用来捕捉每个特征与标签之间的线性关系的过滤方法。它即可以做回归也可以做分类，因此包含feature_selection.f_classif（F检验分类）和feature_selection.f_regression（F检验回归）两个类。其中F检验分类用于标签是离散型变量的数据，而F检验回归用于标签是连续型变量的数据。\n",
    "\n",
    "F检验的本质是寻找两组数据之间的线性关系，其原假设是”数据不存在显著的线性关系“。它返回F值和p值两个统计量。和卡方过滤一样，我们希望选取p值小于0.05或0.01的特征，这些特征与标签时显著线性相关的，而p值大于0.05或0.01的特征则被我们认为是和标签没有显著线性关系的特征，应该被删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 618.65383492,  846.18897012, 1115.40617051, 1362.3677305 ,\n",
       "       1452.03355369, 1381.09095571, 1138.26505266,  464.29616121,\n",
       "        660.00977785,  849.66393412, 1004.7450309 , 1124.76177588,\n",
       "       1200.99190762, 1209.29489877, 1110.4944286 ,  854.66183292,\n",
       "        577.52063451,  342.09729054,  178.67397866,  118.01145533,\n",
       "        612.12261014,  899.40904291, 1196.17528948, 1424.49864852,\n",
       "       1569.26556677, 1742.49910702, 1910.98023795, 1969.20520223,\n",
       "       1731.37475948, 1295.09668012,  839.15325001,  531.97951763,\n",
       "        371.82392681,  336.00820537,  378.93378743,  317.47025479,\n",
       "        528.94881012,  766.40792176,  947.63168717, 1086.0472161 ,\n",
       "       1177.72017709, 1253.79641973, 1344.06961068, 1507.33781169,\n",
       "       1616.50454434, 1512.25864876, 1289.65180587, 1051.26276412,\n",
       "        839.48869386,  680.07426932,  600.85538567,  633.55772663,\n",
       "        683.96908509,  347.65867784,  452.76238211,  509.16387684,\n",
       "        515.7498157 ,  532.86107778,  594.62512658,  664.18740444,\n",
       "        709.37133696,  798.11767931,  876.69849088,  852.76926441,\n",
       "        785.70173347,  802.88980095,  813.2041131 ,  760.85552527,\n",
       "        687.94148028,  642.84071735,  698.11530217,  367.16414289,\n",
       "        455.90449427,  485.50500277,  476.23046034,  536.72332365,\n",
       "        740.12587382, 1041.38089649, 1168.8028973 ,  941.91083922,\n",
       "        795.72843454,  861.29818828,  868.19464432,  838.80173567,\n",
       "        886.26659655,  959.12740961,  934.56890789,  783.1988476 ,\n",
       "        631.01107034,  542.02937189,  493.83337615,  533.27899195,\n",
       "        572.34131749,  657.20547321,  981.66873526, 1465.82267956,\n",
       "       1756.05831022, 1385.28086085,  798.73125604,  761.40508874,\n",
       "       1062.6919609 ,  979.38193965,  947.82602644, 1085.00522683,\n",
       "       1152.13801689, 1118.1595422 , 1021.13086631,  812.37823266,\n",
       "        509.86857625,  411.37986706,  430.7150329 ,  545.55866945,\n",
       "        829.92259533, 1376.4852629 , 1811.62922878, 1601.33613631,\n",
       "        898.8719158 ,  417.37765921,  895.77244253, 1455.38592931,\n",
       "        956.2421521 ,  990.1748413 , 1359.47406197, 1279.27992017,\n",
       "       1166.80888121, 1291.41792351, 1263.86987819,  787.81807986,\n",
       "        237.21811742,  333.12552194,  621.47324186, 1139.04489426,\n",
       "       1713.54508435, 1823.42451065, 1436.53069242,  884.19442779,\n",
       "        717.63373994, 2026.90370414, 2219.46450157,  943.55587655,\n",
       "       1217.29127813, 1677.03878308, 1193.63540136, 1039.56842784,\n",
       "       1570.18098323, 1878.5600272 , 1284.78903715,  190.02740438,\n",
       "        444.17019739,  928.80156872, 1562.54171587, 1940.54801063,\n",
       "       1816.57346013, 1683.83193784, 1619.17496376, 1865.78706551,\n",
       "       3482.82350415, 2326.10253286,  990.67999393, 1632.46650414,\n",
       "       1652.51500198,  891.26746579,  883.96689508, 1805.57103626,\n",
       "       2389.97435433, 1630.34926872,  301.84091297,  746.3286491 ,\n",
       "       1394.82469151, 2008.19411716, 2107.3680475 , 1767.97892382,\n",
       "       1786.08753011, 1980.1986791 , 2509.14739387, 3366.13986444,\n",
       "       1959.90573326, 1299.36608875, 2218.28123025, 1470.25657381,\n",
       "        681.02610086,  937.54741741, 2037.45812231, 2518.68810085,\n",
       "       1583.0009463 ,  509.76276636, 1139.21364745, 1881.71834116,\n",
       "       2351.30851824, 2175.48525458, 1624.49647062, 1399.44534221,\n",
       "       1440.98664744, 2229.25720739, 2764.00452882, 1633.74258116,\n",
       "       1870.29253742, 2628.79930504, 1367.31440177,  707.38857243,\n",
       "       1150.06936228, 2089.08213594, 2185.00557858, 1318.14722036,\n",
       "        747.37697661, 1453.94015412, 2116.40726513, 2399.53090598,\n",
       "       2143.53519978, 1651.89817908, 1414.71662551, 1481.62100314,\n",
       "       2468.21266727, 2666.18025642, 1520.6400065 , 2223.14029953,\n",
       "       2271.07109628, 1111.06997494,  844.31183874, 1388.60413626,\n",
       "       1917.10207189, 1667.61400215,  996.09054823,  907.80926355,\n",
       "       1607.70263546, 2085.21461056, 2073.68356276, 1880.26929744,\n",
       "       1756.40165025, 1716.45478479, 1964.08537105, 2796.13761562,\n",
       "       2413.09378391, 1543.01310963, 2118.10377396, 1475.29541488,\n",
       "        783.59003763, 1040.65400476, 1582.46200024, 1617.32566033,\n",
       "       1188.24554305,  642.2665701 , 1011.30241064, 1725.70185142,\n",
       "       2067.20755476, 1893.35116837, 1795.96538455, 1922.58627318,\n",
       "       1951.69309645, 2115.44871238, 2479.27958039, 1809.12095649,\n",
       "       1330.8686207 , 1396.29767244,  741.9063402 ,  751.14036409,\n",
       "       1410.18529816, 1677.6595494 , 1308.77910167,  836.77047561,\n",
       "        430.93133677,  313.888671  , 1039.31894918, 1811.68171256,\n",
       "       2191.69964967, 2035.63638826, 2114.65218363, 2511.27142071,\n",
       "       2363.46743373, 2053.7687027 , 1865.84769096, 1202.94179711,\n",
       "        793.61414555,  633.71267282,  636.18282736, 1218.61245591,\n",
       "       1712.62901816, 1484.60290068,  996.06129466,  626.13659134,\n",
       "        441.56356583,  374.08815796,  983.21640593, 1764.93014215,\n",
       "       2264.93587233, 2262.87269162, 2323.50890468, 2611.66920897,\n",
       "       2387.45723028, 1763.5696083 , 1256.32165954,  704.77285945,\n",
       "        406.94580935,  548.06969664, 1051.50016486, 1542.11172909,\n",
       "       1494.38472469, 1130.61174365,  823.84437277,  650.69506052,\n",
       "        594.18011033,  415.73313115,  853.97575783, 1548.7167469 ,\n",
       "       2204.00694989, 2444.69535795, 2267.62871155, 2003.69161124,\n",
       "       1643.94961527, 1202.35520102,  804.18805494,  483.32932365,\n",
       "        420.99263006,  750.06949525, 1136.32227345, 1202.49476981,\n",
       "        990.75097727,  791.03016258,  692.46641159,  653.96372577,\n",
       "        647.90433225, 1149.80460733, 1826.54973661, 2361.75564926,\n",
       "       2313.09139096, 1694.26613916, 1012.97938867,  608.4174945 ,\n",
       "        432.07115684,  383.54620406,  487.70312805,  698.78061024,\n",
       "        797.0763827 ,  714.70722998,  574.2849126 ,  507.5143557 ,\n",
       "        508.77434021,  510.36884435,  404.13860698,  686.31274396,\n",
       "       1103.81003251, 1590.83695172, 1912.74984902, 1832.62220523,\n",
       "       1482.39046946, 1142.10827805,  968.65089356,  860.24853405,\n",
       "        780.75215696,  696.78170045,  567.41403081,  403.59649375,\n",
       "        284.91007929,  245.59060983,  255.97458001,  293.6787996 ,\n",
       "        460.46868009,  687.29383613,  940.06512113, 1205.58777055,\n",
       "       1485.37178744, 1623.12886955, 1488.04856361, 1119.91615126,\n",
       "        770.06544455,  530.6398126 ,  376.66549502,  258.05875548,\n",
       "        172.20323661,  123.79865884,  160.44132806,  249.15104257,\n",
       "        374.15221131,  544.73535425,  727.78945347,  853.98680046,\n",
       "        819.19801306,  656.55547718,  510.87851723,  445.09613969,\n",
       "        401.25608847,  333.48574029,  243.88699402,  645.9545719 ,\n",
       "        920.3259526 , 1196.07900013, 1308.12260763, 1218.37705687,\n",
       "        996.41501921,  792.59409228,  663.47516843,  550.14745143])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "F,pvalue_f = f_classif(X_fsvar,y)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 4.71193533e-220,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       3.26083326e-322, 5.24336441e-231, 4.04009647e-300, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_f #p值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = F.shape[0] - (pvalue_f > 0.05).sum()\n",
    "#X_fsF = SelectKBest(f_classif, k=填写具体的k).fit_transform(X_fsvar, y)\n",
    "#cross_val_score(RFC(n_estimators=10,random_state=0),X_fsF,y,cv=5).mean()\n",
    "'''得到的结论和我们用卡方过滤得到的结论一样，没有任何特征的p值大于0.01，所有的特征都是和标签相关的，因此我们不\n",
    "需要相关性过滤'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 互信息法\n",
    "互信息法是用来捕捉每个特征与标签之间的任意关系（包括线性和非线性关系）的过滤方法。和F检验相似，它既可以做回归也可以做分类，并且包含两个类feature_selection.mutual_info_classif（互信息分类）和feature_selection.mutual_info_regression（互信息回归）。这两个类的用法和参数都和F检验一模一样，不过互信息法比F检验更加强大，F检验只能够找出线性关系，而互信息法可以找出任意关系。\n",
    "\n",
    "互信息法不返回p值或F值类似的统计量，它返回“每个特征与目标之间的互信息量的估计”，这个估计量在[0,1]之间取值，为0则表示两个变量独立，为1则表示两个变量完全相关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06681521, 0.08291998, 0.10203694, 0.10784021, 0.11895237,\n",
       "       0.10547898, 0.07890212, 0.06023902, 0.0766079 , 0.10380274,\n",
       "       0.11743519, 0.14033474, 0.16212552, 0.1662196 , 0.15483579,\n",
       "       0.12349968, 0.09344723, 0.06428739, 0.03491352, 0.02311557,\n",
       "       0.07129902, 0.09810594, 0.12301126, 0.15487827, 0.17589627,\n",
       "       0.20106568, 0.2263199 , 0.23368167, 0.21298679, 0.17643577,\n",
       "       0.13655157, 0.10539107, 0.07789478, 0.0574883 , 0.04300093,\n",
       "       0.03747105, 0.05626434, 0.07527011, 0.1070962 , 0.12366859,\n",
       "       0.13530655, 0.15061015, 0.16192886, 0.18534429, 0.1855935 ,\n",
       "       0.17278143, 0.1599068 , 0.12789034, 0.11402559, 0.09368799,\n",
       "       0.08133324, 0.06940836, 0.06585639, 0.04899127, 0.05400329,\n",
       "       0.07552079, 0.08430276, 0.09597843, 0.1089208 , 0.10893958,\n",
       "       0.11251933, 0.10984294, 0.12330751, 0.11672659, 0.1055326 ,\n",
       "       0.11373392, 0.11494545, 0.10270779, 0.08612445, 0.07452045,\n",
       "       0.06678861, 0.04141912, 0.04887087, 0.0686945 , 0.07352346,\n",
       "       0.09487439, 0.11628939, 0.14078735, 0.14213907, 0.1145805 ,\n",
       "       0.10612103, 0.1200935 , 0.11174317, 0.11536792, 0.12645021,\n",
       "       0.1339905 , 0.12419031, 0.10727821, 0.08319514, 0.07103445,\n",
       "       0.04855468, 0.05754346, 0.07241349, 0.09424919, 0.13630878,\n",
       "       0.18742894, 0.20439804, 0.16052592, 0.10883587, 0.10016033,\n",
       "       0.13183497, 0.11934846, 0.13080085, 0.135386  , 0.15376516,\n",
       "       0.14472363, 0.12548012, 0.08902227, 0.06644626, 0.03799342,\n",
       "       0.05735477, 0.08273409, 0.12136326, 0.17961506, 0.21971246,\n",
       "       0.19609254, 0.12300801, 0.072779  , 0.10654653, 0.14769339,\n",
       "       0.11475393, 0.13297176, 0.16101004, 0.16105766, 0.14221938,\n",
       "       0.12934509, 0.10830234, 0.07266078, 0.02776644, 0.05239514,\n",
       "       0.09365825, 0.15536169, 0.20776975, 0.22232087, 0.17744923,\n",
       "       0.11199011, 0.10733599, 0.17953313, 0.1859256 , 0.12323647,\n",
       "       0.14859239, 0.17134586, 0.15578953, 0.14028775, 0.14190703,\n",
       "       0.11335882, 0.0797004 , 0.03039686, 0.0698647 , 0.13050693,\n",
       "       0.1902674 , 0.23009475, 0.22150774, 0.19889906, 0.17165282,\n",
       "       0.19414409, 0.26139937, 0.2173221 , 0.14328315, 0.17785598,\n",
       "       0.18944345, 0.13861693, 0.13022401, 0.14933056, 0.13388232,\n",
       "       0.09757027, 0.04520627, 0.09932578, 0.15372697, 0.20951424,\n",
       "       0.22962401, 0.20767878, 0.19609835, 0.20057667, 0.25188377,\n",
       "       0.28655329, 0.2105781 , 0.17170241, 0.2201799 , 0.17799136,\n",
       "       0.11435094, 0.11389628, 0.15755067, 0.15099026, 0.1012342 ,\n",
       "       0.06395639, 0.118561  , 0.17411574, 0.21751816, 0.22563922,\n",
       "       0.19749776, 0.1819932 , 0.18984628, 0.24852151, 0.28422802,\n",
       "       0.19794469, 0.20964681, 0.25050842, 0.18458211, 0.12359868,\n",
       "       0.13807431, 0.16143815, 0.14113143, 0.09397897, 0.07388952,\n",
       "       0.13157261, 0.19355274, 0.22344313, 0.22168856, 0.19513995,\n",
       "       0.16767993, 0.1928935 , 0.25852082, 0.27244008, 0.1989776 ,\n",
       "       0.23367499, 0.23757447, 0.1706503 , 0.12774535, 0.14924847,\n",
       "       0.16472471, 0.12689839, 0.08527095, 0.07934814, 0.1363275 ,\n",
       "       0.19041349, 0.20546578, 0.1969429 , 0.18742407, 0.18263918,\n",
       "       0.22097192, 0.26650439, 0.24819175, 0.18567878, 0.20942479,\n",
       "       0.17898937, 0.13069451, 0.13971721, 0.16915986, 0.15005237,\n",
       "       0.11255069, 0.07444784, 0.09093388, 0.14119962, 0.18351708,\n",
       "       0.19012514, 0.18959774, 0.19760177, 0.20123248, 0.22102409,\n",
       "       0.24876396, 0.20044072, 0.1477152 , 0.15414789, 0.13062041,\n",
       "       0.12202213, 0.17325401, 0.17896643, 0.1425844 , 0.10296063,\n",
       "       0.05845451, 0.03905167, 0.10100042, 0.14981067, 0.18894282,\n",
       "       0.19680488, 0.19534608, 0.20979975, 0.21760435, 0.20345401,\n",
       "       0.19715057, 0.14479275, 0.10190434, 0.09714591, 0.111246  ,\n",
       "       0.15568554, 0.19639618, 0.17215227, 0.12910582, 0.09145454,\n",
       "       0.0539177 , 0.0472992 , 0.10585256, 0.16478476, 0.20232604,\n",
       "       0.21900025, 0.21528268, 0.21852929, 0.2050272 , 0.16584481,\n",
       "       0.14247983, 0.09576557, 0.07589701, 0.07996356, 0.14258547,\n",
       "       0.18405496, 0.18845521, 0.14832448, 0.11488417, 0.08554106,\n",
       "       0.06160258, 0.04882261, 0.10502491, 0.1637101 , 0.21914432,\n",
       "       0.24213962, 0.23836816, 0.2151082 , 0.17930417, 0.13971844,\n",
       "       0.10670212, 0.07059467, 0.06670438, 0.10442619, 0.14441146,\n",
       "       0.16121498, 0.14811701, 0.11519309, 0.09145469, 0.06416434,\n",
       "       0.0900069 , 0.1397643 , 0.20160763, 0.22748802, 0.23558766,\n",
       "       0.19189829, 0.13561955, 0.10276763, 0.07359825, 0.06543829,\n",
       "       0.08017736, 0.09934251, 0.12356864, 0.11382385, 0.09136443,\n",
       "       0.08128239, 0.05536312, 0.05082449, 0.06233587, 0.1028112 ,\n",
       "       0.14909469, 0.18412244, 0.19741177, 0.18546147, 0.16592693,\n",
       "       0.13673588, 0.11688018, 0.10953326, 0.10208324, 0.10374473,\n",
       "       0.08861041, 0.07244464, 0.05897959, 0.04540639, 0.0324467 ,\n",
       "       0.0520586 , 0.08344581, 0.10431503, 0.13404456, 0.15684952,\n",
       "       0.16889402, 0.18244268, 0.18235723, 0.15384151, 0.12802772,\n",
       "       0.09678177, 0.07508318, 0.05136857, 0.03799071, 0.0252156 ,\n",
       "       0.03187433, 0.04370872, 0.06258233, 0.08583738, 0.10139241,\n",
       "       0.12479256, 0.12033421, 0.10725685, 0.09312406, 0.07614347,\n",
       "       0.06416346, 0.03941546, 0.03581602, 0.05678828, 0.09068582,\n",
       "       0.10469222, 0.11543029, 0.11142233, 0.10270203, 0.08441456,\n",
       "       0.07433006, 0.05428848])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "\n",
    "result = MIC(X_fsvar,y)\n",
    "k = result.shape[0] - sum(result <= 0)\n",
    "\n",
    "#X_fsmic = SelectKBest(MIC, k=填写具体的k).fit_transform(X_fsvar, y)\n",
    "#cross_val_score(RFC(n_estimators=10,random_state=0),X_fsmic,y,cv=5).mean()Tsai Ts\n",
    "'''所有特征的互信息量估计都大于0，因此所有特征都与标签相关'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](1579531077(1).jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded嵌入法\n",
    "嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。在使用嵌入法时，我们先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小选择特征。这些权值系数往往代表了特征对于模型的某种贡献或某种重要性，比如决策树和树的集成模型中的feature_importances_属性，可以列出各个特征对树的建立的贡献，我们就可以基于这种贡献的评估，找出对模型建立最有用的特征。因此相比于过滤法，嵌入法的结果会更加精确到模型的效用本身，对于提高模型效力有更好的效果。并且，由于考虑特征对模型的贡献，因此无关的特征（需要相关性过滤的特征）和无区分度的特征（需要方差过滤的特征）都会因为缺乏对模型的贡献而被删除掉，可谓是过滤法的进化版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature_selection.SelectFromModel\n",
    "classsklearn.feature_selection.SelectFromModel(estimator, threshold=None, prefit=False, norm_order=1,max_features=None)\n",
    "\n",
    "SelectFromModel是一个元变换器，可以与任何在拟合后具有coef_，feature_importances_属性或参数中可选惩罚项的评估器一起使用（比如随机森林和树模型就具有属性feature_importances_，逻辑回归就带有l1和l2惩罚项，线性支持向量机也支持l2惩罚项）\n",
    "\n",
    "对于有feature_importances_的模型来说，若重要性低于提供的阈值参数，则认为这些特征不重要并被移除。feature_importances_的取值范围是[0,1]，如果设置阈值很小，比如0.001，就可以删除那些对标签预测完全没贡献的特征。如果设置得很接近1，可能只有一两个特征能够被留下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'重要参数:\\nestimator:使用的模型评估器，只要是带feature_importances_或者coef_属性，或带有l1和l2惩罚项的模型都可以使用\\nthreshold:特征重要性的阈值，重要性低于这个阈值的特征都将被删除\\nprefit：默认False，判断是否将实例化后的模型直接传递给构造函数。如果True，则必须直接调用fit和transform，不能使用\\n        fit_transform,并且SelectFromModel不能与cross_val_score,GridSearchCV和克隆估计器的类似实用程序一起使用。\\nnorm_order:k可输入非零整数，正无穷，负无穷，默认值为1 在评估器的coef_属性高于一维的情况下，用于过滤低于阈值的系\\n            数的向量的范数的阶数\\nmax_features:在阈值设定下，要选择的最大特征数。要禁用阈值并仅根据max_features选择，请设置threshold = -np.inf'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''重要参数:\n",
    "estimator:使用的模型评估器，只要是带feature_importances_或者coef_属性，或带有l1和l2惩罚项的模型都可以使用\n",
    "threshold:特征重要性的阈值，重要性低于这个阈值的特征都将被删除\n",
    "prefit：默认False，判断是否将实例化后的模型直接传递给构造函数。如果True，则必须直接调用fit和transform，不能使用\n",
    "        fit_transform,并且SelectFromModel不能与cross_val_score,GridSearchCV和克隆估计器的类似实用程序一起使用。\n",
    "norm_order:k可输入非零整数，正无穷，负无穷，默认值为1 在评估器的coef_属性高于一维的情况下，用于过滤低于阈值的系\n",
    "            数的向量的范数的阶数\n",
    "max_features:在阈值设定下，要选择的最大特征数。要禁用阈值并仅根据max_features选择，请设置threshold = -np.inf'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 47)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "RFC_ = RFC(n_estimators = 10,random_state=0)\n",
    "    \n",
    "X_embedded = SelectFromModel(RFC_,threshold=0.005).fit_transform(X,y)\n",
    "#在这里我只想取出来有限的特征。0.005这个阈值对于有780个特征的数据来说，是非常高的阈值，因为\n",
    "#平均每个特征只能够分到大约0.001的feature_importances_\n",
    "X_embedded.shape #模型的维度明显被降低了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importance:[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 4.96726660e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.39623410e-06\n",
      " 7.35101726e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 4.70425050e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.09114204e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.04375545e-05\n",
      " 0.00000000e+00 0.00000000e+00 5.29478959e-05 3.21066639e-04\n",
      " 3.72896708e-05 7.84734515e-05 3.81080672e-05 4.28007718e-05\n",
      " 7.70708109e-06 4.96573475e-05 1.07617170e-04 1.68715849e-05\n",
      " 1.17836211e-05 2.55943987e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.98169346e-06 4.94027841e-06 2.83311486e-05\n",
      " 4.09543756e-05 1.72821858e-04 9.57100915e-05 2.45907321e-04\n",
      " 1.83422252e-04 1.67021648e-03 1.33678817e-03 4.97681606e-04\n",
      " 9.81528697e-04 2.57107282e-03 1.29146589e-03 1.65060000e-03\n",
      " 1.86071384e-04 9.53324105e-05 2.15756468e-05 1.93742313e-05\n",
      " 1.76038786e-05 1.04294263e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.67461542e-05 6.87034035e-06 7.72427467e-05\n",
      " 1.32367326e-04 1.90286903e-04 5.95754392e-04 1.20094659e-03\n",
      " 8.38179934e-04 1.55287193e-03 1.25015678e-03 3.10076865e-03\n",
      " 3.53710687e-03 6.09457703e-04 4.40384898e-04 6.77374025e-04\n",
      " 5.30201989e-04 1.79987666e-04 1.82267211e-04 5.92697964e-05\n",
      " 1.80767363e-05 5.24921596e-06 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 3.63793673e-05 6.43483201e-05 8.13740620e-05 1.76906929e-04\n",
      " 3.00785753e-04 2.00237912e-03 2.17988175e-03 8.02080061e-04\n",
      " 5.59932650e-03 5.32674802e-03 9.82923375e-03 4.75128066e-03\n",
      " 7.25896751e-03 2.57320673e-03 6.13199153e-03 2.79002672e-03\n",
      " 8.60740254e-04 1.68934107e-03 6.62626894e-04 3.72068454e-04\n",
      " 1.11864559e-04 5.01402939e-06 2.59729852e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.24370634e-06\n",
      " 5.39166565e-05 3.11018823e-05 2.34878167e-04 3.89033229e-04\n",
      " 2.30902923e-03 2.57256846e-03 1.38900529e-03 2.65304800e-03\n",
      " 4.67867505e-03 3.49571544e-03 1.74013763e-03 4.74732141e-03\n",
      " 2.19504075e-03 2.01126998e-03 2.39322271e-03 1.94485134e-03\n",
      " 1.91736734e-03 1.26111979e-03 7.17005718e-04 1.41834376e-03\n",
      " 2.47847664e-04 4.23798505e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.64644966e-06 1.02232772e-05\n",
      " 4.19366739e-05 1.51187645e-04 3.84353726e-04 5.75432437e-04\n",
      " 1.20251320e-03 1.11728097e-03 1.43117176e-03 1.85993731e-03\n",
      " 3.18900495e-03 4.24721472e-03 7.15525695e-03 4.59547276e-03\n",
      " 7.86762226e-03 4.41108734e-03 1.54578735e-03 1.06705126e-03\n",
      " 1.49258829e-03 1.28480766e-03 9.93716659e-04 1.33748351e-03\n",
      " 1.04061523e-03 1.40851781e-04 2.46917895e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.23372533e-05 1.91675705e-05\n",
      " 2.16315147e-04 2.36117271e-04 8.51271969e-04 7.04486223e-04\n",
      " 1.07859246e-03 1.64029329e-03 2.90544958e-03 3.15084018e-03\n",
      " 4.87802961e-03 2.34634670e-03 3.93852105e-03 5.43460799e-03\n",
      " 5.86237142e-03 3.15346289e-03 6.82349562e-03 4.34223264e-03\n",
      " 3.86949586e-03 2.03220256e-03 7.00743969e-04 1.01816134e-03\n",
      " 6.52755553e-04 1.05428274e-04 4.64072405e-06 8.60096309e-06\n",
      " 0.00000000e+00 9.18662879e-06 7.05716770e-06 2.57599316e-05\n",
      " 6.82385198e-05 2.48904426e-04 1.27880958e-03 1.34106798e-03\n",
      " 9.88188421e-04 2.10154796e-03 3.36772807e-03 6.04369789e-03\n",
      " 3.07695369e-03 3.00021995e-03 3.37748090e-03 4.86394760e-03\n",
      " 3.54139826e-03 5.97819039e-03 1.71616932e-03 4.15596755e-03\n",
      " 2.47392287e-03 2.36136390e-03 1.63397286e-03 4.48393070e-04\n",
      " 5.54092223e-04 4.14227893e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.26899634e-06 1.56088268e-04\n",
      " 1.13966961e-04 1.74915348e-04 6.44627258e-04 5.68303338e-04\n",
      " 1.63319806e-03 4.62162655e-03 5.83028006e-03 5.84100388e-03\n",
      " 2.83270210e-03 2.14239040e-03 3.35948722e-03 2.60839810e-03\n",
      " 2.50701816e-03 4.82670205e-03 5.89666662e-03 3.04992055e-03\n",
      " 3.41911464e-03 1.12637810e-03 7.01707700e-04 2.10535503e-04\n",
      " 2.04943891e-04 6.40794860e-05 2.64614091e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.52876307e-06 1.73010344e-05\n",
      " 3.23154454e-04 1.18730749e-04 5.01029809e-04 1.50202308e-03\n",
      " 1.53700272e-03 6.11456403e-03 4.34902573e-03 3.35546394e-03\n",
      " 5.87789239e-03 2.51293898e-03 3.17370607e-03 3.45751913e-03\n",
      " 2.29793132e-03 4.17392058e-03 5.82675966e-03 2.83060606e-03\n",
      " 3.79048860e-03 1.04936114e-03 7.03677686e-04 6.28439770e-04\n",
      " 1.15259208e-04 7.44590415e-05 1.04994603e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.58480368e-05 8.38015968e-06\n",
      " 7.29727487e-05 4.58356454e-04 5.41496181e-04 1.05167245e-03\n",
      " 1.64596693e-03 3.00082596e-03 5.53132168e-03 4.04488155e-03\n",
      " 2.62974709e-03 5.05500552e-03 6.96693959e-03 3.39745427e-03\n",
      " 3.32871913e-03 3.41607543e-03 2.74289623e-03 1.34605792e-03\n",
      " 1.28266397e-03 2.86907034e-03 4.37592501e-03 5.70010069e-04\n",
      " 6.28420535e-05 8.66985846e-06 1.88614134e-05 0.00000000e+00\n",
      " 0.00000000e+00 5.07941099e-06 0.00000000e+00 3.30247867e-05\n",
      " 4.07335970e-05 2.06942431e-04 1.13712177e-03 9.31937042e-04\n",
      " 4.14319758e-03 5.55092635e-03 3.00151203e-03 3.90947224e-03\n",
      " 3.56773974e-03 6.51955884e-03 9.53149654e-03 1.04694058e-02\n",
      " 2.78585321e-03 3.32633681e-03 4.92832778e-03 1.47824275e-03\n",
      " 9.11054702e-04 7.61598938e-04 2.70451017e-03 5.35404177e-04\n",
      " 9.96457782e-05 3.14222399e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.96978697e-06 5.21588243e-06\n",
      " 4.83166769e-05 2.73878244e-04 7.87729782e-04 1.50109957e-03\n",
      " 4.68533446e-03 3.87612563e-03 5.67003476e-03 2.36023388e-03\n",
      " 5.93148815e-03 4.71373442e-03 5.52560277e-03 1.02884076e-02\n",
      " 4.29557610e-03 1.12774927e-02 2.77441947e-03 2.72491516e-03\n",
      " 1.44030628e-03 4.10553375e-03 2.64943685e-04 5.11833536e-04\n",
      " 1.40472270e-04 1.79084679e-05 1.77952716e-05 5.14181932e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.05843388e-05\n",
      " 1.27523758e-04 6.43468836e-04 8.31565905e-04 1.70449912e-03\n",
      " 1.97585662e-03 1.03326213e-02 6.51715463e-03 2.51474500e-03\n",
      " 4.45321356e-03 9.25048608e-03 5.64462078e-03 4.37348237e-03\n",
      " 2.48720699e-03 6.86810239e-03 1.74833765e-03 1.26700872e-03\n",
      " 9.76402337e-04 1.14948866e-03 1.12740475e-03 3.55493697e-04\n",
      " 1.65851188e-04 5.68633276e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.66021879e-05 5.45348998e-05\n",
      " 4.59211388e-05 2.34098914e-04 5.06234432e-03 4.27063479e-03\n",
      " 2.39257951e-03 4.61990114e-03 3.30496636e-03 3.33854229e-03\n",
      " 3.32969638e-03 6.80014826e-03 2.53704828e-03 1.90375781e-03\n",
      " 2.48951700e-03 3.25158138e-03 2.31606267e-03 1.80236457e-03\n",
      " 1.17266716e-03 8.52676338e-04 4.79005366e-04 3.50563863e-04\n",
      " 1.56906559e-04 2.49268946e-05 1.03169010e-05 8.82122072e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.90546235e-05\n",
      " 7.88704875e-05 8.93634610e-04 6.94020542e-04 1.20345523e-03\n",
      " 2.54044035e-03 2.83230622e-03 4.09933983e-03 3.29395754e-03\n",
      " 7.25903583e-03 9.87880420e-03 1.00977121e-02 3.13706882e-03\n",
      " 1.45463444e-03 2.30625167e-03 4.36681075e-03 1.40686900e-03\n",
      " 7.71080832e-04 4.72573500e-04 6.92470927e-04 2.10882278e-04\n",
      " 1.59887529e-04 4.25095501e-05 9.34580618e-06 5.17727569e-06\n",
      " 0.00000000e+00 0.00000000e+00 8.49057021e-06 8.09379015e-05\n",
      " 1.52667865e-04 2.94682754e-04 1.35550050e-03 4.49735800e-03\n",
      " 1.28105089e-03 2.31970006e-03 2.34781587e-03 1.27636021e-02\n",
      " 2.19523640e-03 2.41654975e-03 2.10844302e-03 1.71325263e-03\n",
      " 8.69359356e-04 3.91492035e-03 6.91924396e-03 1.10238422e-03\n",
      " 1.33621731e-03 1.34601819e-03 9.33978020e-04 2.82706898e-04\n",
      " 1.17855133e-04 7.23606373e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.93842272e-06 2.30929786e-04\n",
      " 1.09578044e-04 9.39787779e-04 2.50398713e-03 1.77156509e-03\n",
      " 2.03739208e-03 9.54215286e-03 2.52326238e-03 2.97043796e-03\n",
      " 4.37234458e-03 1.99656347e-03 3.08114892e-03 1.65516988e-03\n",
      " 1.07792201e-03 2.44342936e-03 1.22032946e-03 5.26252267e-03\n",
      " 8.27756677e-04 8.44727742e-04 3.68115383e-04 1.73202448e-04\n",
      " 1.26854745e-04 1.52414678e-05 1.04038762e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.76744549e-05\n",
      " 1.83409930e-04 1.45882648e-03 1.00645114e-03 3.27870252e-03\n",
      " 2.13913782e-03 6.13495296e-03 3.50175122e-03 3.52761230e-03\n",
      " 2.75623799e-03 3.97448421e-03 1.44302862e-03 1.75858337e-03\n",
      " 1.51206834e-03 1.46700318e-03 9.08321557e-04 2.22925996e-03\n",
      " 1.48254286e-03 8.57378425e-04 3.99971776e-04 5.11110295e-04\n",
      " 4.36565498e-05 2.71405310e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 4.68939741e-06 6.85322336e-05\n",
      " 7.32909456e-04 3.69494001e-04 9.37742251e-04 3.11084738e-03\n",
      " 2.51401499e-03 4.48363496e-03 2.22316180e-03 1.09418645e-03\n",
      " 1.98315806e-03 1.07395133e-03 1.21395404e-03 1.90010236e-03\n",
      " 1.07770399e-03 9.46524339e-04 7.22390654e-04 8.23678460e-04\n",
      " 4.86429638e-04 1.69959091e-03 2.30072266e-04 1.58290498e-04\n",
      " 7.08265381e-05 1.03258860e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.37481499e-05\n",
      " 1.24712280e-04 1.34419610e-04 7.17713513e-04 9.41939756e-04\n",
      " 4.60329650e-03 4.77462409e-03 2.66748761e-03 2.03891226e-03\n",
      " 1.56470228e-03 1.41617812e-03 1.28207400e-03 1.42887646e-03\n",
      " 8.46671326e-04 1.77447428e-03 1.51782753e-03 6.33095101e-04\n",
      " 6.30765641e-04 2.88161403e-04 3.05029795e-04 1.12466566e-04\n",
      " 2.75681464e-05 4.55441849e-06 5.16468244e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.08305424e-06 4.89332518e-06\n",
      " 2.46008387e-05 8.31376723e-05 4.79932393e-04 3.30739912e-04\n",
      " 1.10543090e-03 3.08453861e-03 4.17801871e-03 2.49670681e-03\n",
      " 4.16378285e-03 5.66440415e-03 7.09175694e-03 2.36066429e-03\n",
      " 1.03455291e-03 5.95763775e-04 8.25377463e-04 3.50173207e-04\n",
      " 4.44834129e-04 2.05457739e-04 5.33080607e-05 4.73933260e-05\n",
      " 3.56526224e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.46238647e-06\n",
      " 2.83095572e-05 5.78206819e-05 4.26331449e-04 2.66286043e-04\n",
      " 4.55553332e-04 1.15799246e-03 1.06486385e-03 2.11733743e-03\n",
      " 1.66150100e-03 8.66222042e-04 6.60990575e-04 2.55402546e-03\n",
      " 8.20486729e-04 4.02940501e-04 3.85855702e-04 2.47553529e-04\n",
      " 1.37233373e-04 1.16468104e-04 4.81919631e-05 3.69201614e-05\n",
      " 9.72640279e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.09401975e-05 2.97450544e-05 1.83375003e-04\n",
      " 3.00031936e-04 9.79359848e-04 4.42908891e-04 3.62099959e-04\n",
      " 6.54463181e-04 8.79186101e-04 4.47248554e-04 6.65237461e-04\n",
      " 6.91068725e-04 3.22617137e-04 4.43746743e-04 2.16706421e-04\n",
      " 3.38144020e-04 7.56933474e-05 1.79747927e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 7.44476502e-06 1.16079201e-05 0.00000000e+00 1.46280748e-05\n",
      " 5.17941553e-06 5.09921173e-05 7.41857827e-05 3.93379316e-04\n",
      " 2.47452360e-04 3.13251304e-04 3.66999099e-04 1.30812201e-04\n",
      " 1.49054545e-04 8.38358796e-05 1.24210033e-04 4.89363342e-05\n",
      " 1.42399445e-05 4.85723858e-06 0.00000000e+00 1.54516611e-05\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.68555485e-06 0.00000000e+00\n",
      " 4.37879533e-06 0.00000000e+00 0.00000000e+00 1.01252722e-05\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 7.93909865e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#同样的，我们也可以画学习曲线来找最佳阈值\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('feature importance:{}'.format(RFC_.fit(X,y).feature_importances_))\n",
    "\n",
    "threshold = np.linspace(0,(RFC_.fit(X,y).feature_importances_).max(),20)\n",
    "\n",
    "score = []\n",
    "for i in threshold:\n",
    "    X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_embedded,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.plot(threshold,score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_embedded.shape:(42000, 324)\n",
      "cross_val_score:0.939905083368037\n"
     ]
    }
   ],
   "source": [
    "'''从图像上来看，随着阈值越来越高，模型的效果逐渐变差，被删除的特征越来越多，信息损失也逐渐变大。\n",
    "但是在0.00134之前，模型的效果都可以维持在0.93以上，因此我们可以从中挑选一个数值来验证一下模型的效果。'''\n",
    "\n",
    "X_embedded = SelectFromModel(RFC_,threshold=0.00067).fit_transform(X,y) #去除部分特征的数据\n",
    "print('X_embedded.shape:{}'.format(X_embedded.shape))\n",
    "print('cross_val_score:{}'.format(cross_val_score(RFC_,X_embedded,y,cv=5).mean()))\n",
    "'''以看出，特征个数瞬间缩小到324多，这比我们在方差过滤的时候选择中位数过滤出来的结果392列要小，\n",
    "并且交叉验证分数0.9399高于方差过滤后的结果0.9388'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 使用细化的学习曲线来找到最佳值\n",
    "score2 = []\n",
    "for i in np.linspace(0,0.00134,20):\n",
    "    X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_embedded,y,cv=5).mean()\n",
    "    score2.append(once)\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(np.linspace(0,0.00134,20),score2)\n",
    "plt.xticks(np.linspace(0,0.00134,20)) #横坐标\n",
    "plt.show()\n",
    "'''查看结果，0.00067并不是最高点，真正的最高点0.00564已经将模型效果提升到94%以上，下面用0.000546来跑一下\n",
    "SelectFromMOdel'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_embedded.shape:(42000, 340)\n",
      "cross_val_score:0.9408335415056387\n"
     ]
    }
   ],
   "source": [
    "X_embedded = SelectFromModel(RFC_,threshold=0.000564).fit_transform(X,y) #删除过相关性低的特征后\n",
    "print('X_embedded.shape:{}'.format(X_embedded.shape))\n",
    "print('cross_val_score:{}'.format(cross_val_score(RFC_,X_embedded,y,cv=5).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Wrapper包装法\n",
    "包装法也是一个特征选择和算法训练同时进行的方法，与嵌入法十分相似，它也是依赖于算法自身的选择，比如coef_属性或feature_importances_属性来完成特征选择。但不同的是，我们往往使用一个目标函数作为黑盒来帮助我们选取特征，而不是自己输入某个评估指标或统计量的阈值。包装法在初始特征集上训练评估器，并且通过coef_属性或通过feature_importances_属性获得每个特征的重要性。然后，从当前的一组特征中修剪最不重要的特征。在修剪的集合上递归地重复该过程，直到最终到达所需数量的要选择的特征。区别于过滤法和嵌入法的一次训练解决所有问题，包装法要使用特征子集进行多次训练，因此它所需要的计算成本是最高的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### feature_selection.RFE\n",
    "classsklearn.feature_selection.RFE(estimator, n_features_to_select=None, step=1, verbose=0)\n",
    "\n",
    "参数estimator是需要填写的实例化后的评估器，n_features_to_select是想要选择的特征个数，step表示每次迭代中希望移除的特征个数。除此之外，RFE类有两个很重要的属性，.support_：返回所有的特征的是否最后被选中的布尔矩阵，以及.ranking_返回特征的按数次迭代中综合重要性的排名。类feature_selection.RFECV会在交叉验证循环中执行RFE以找到最佳数量的特征，增加参数cv，其他用法都和RFE一模一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "RFC_ = RFC(n_estimators=10,random_state=0)\n",
    "selector = RFE(RFC_,n_features_to_select=340,step=50).fit(X,y)\n",
    "print(selector.support_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector.ranking:[10  9  8  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  7  7  6  6  5  6  5  6  6  6  6  6  6  6  6  6  6  7\n",
      "  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  6  6  5  4  4  5  3  4\n",
      "  4  4  5  4  5  7  6  7  7  7  8  8  8  8  8  8  8  8  6  7  4  3  1  2\n",
      "  3  3  1  1  1  1  1  3  3  4  5  5  5  8  8  9  9  9  9  8  9  9  4  4\n",
      "  3  2  1  1  1  1  1  1  1  1  1  1  2  3  3  4  5  5  9  9 10 10 10 10\n",
      "  7  4  4  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  3  3  5  8 10\n",
      " 10 10 10  9  4  4  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  3  4 10 10 10 10  9  7  4  3  2  2  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  2  4  4 10  9 10  6  6  4  2  3  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  3  5  9 10  8  7  4  5  3  2  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  2  1  2  4 10 10 10  9  7  5  3  3  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  3  5  5  9  9  9  7  5\n",
      "  5  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  4  5  9  9\n",
      "  9  9  9  5  4  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  4  5  7 10 10  9 10  9  4  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  3  5 10  9 10 10  9  7  4  2  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  2  2  4  8  9 10 10 10  5  4  2  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  2  3  5 10 10 10 10  9  5  4  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  3  4  5  9 10 10 10  5\n",
      "  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  3  4  8  8\n",
      " 10 10  9  5  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  3\n",
      "  3  4 10 10 10 10  8  4  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  2  4  5  8 10 10 10 10  5  2  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  2  4  7 10 10 10 10  8  5  3  2  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  2  3  3  5  5  7  9  9  9  9  5  5  2  2  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  2  2  2  3  4  5  5  8  9  9  9  9  7\n",
      "  4  4  2  1  1  1  1  1  1  1  1  1  1  1  1  3  3  3  5  5  9  8  9  9\n",
      "  9  9  9  5  4  4  2  2  1  1  1  1  1  2  1  1  1  1  2  2  3  4  5  5\n",
      "  9  8  8  8  8  8  8  7  8  6  4  2  2  1  1  2  2  1  2  2  3  2  2  4\n",
      "  4  5  5  8  8  8  7  7  7  7  7  7  7  5  5  4  5  4  3  3  3  4  3  3\n",
      "  4  3  4  5  5  6  7  7  7  6  7  8  8  8  9  9  9  9  6  8  8  8  7  8\n",
      "  8  8  7  8  8  8  8  8  7  8  8  8  8  9 10  7]\n"
     ]
    }
   ],
   "source": [
    "print('selector.ranking:{}'.format(selector.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9389522459432109"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wrapper = selector.transform(X) #更新后的特征矩阵\n",
    "cross_val_score(RFC_,X_wrapper,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学习曲线\n",
    "score = []\n",
    "for i in range(1,751,50):\n",
    "    X_wrapper = RFE(RFC_,n_features_to_select=i, step=50).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_wrapper,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(range(1,751,50),score)\n",
    "plt.xticks(range(1,751,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择总结\n",
    "经验来说，过滤法更快速，但更粗糙。包装法和嵌入法更精确，比较适合具体到算法去调整，但计算量比较大，运行时间长。当数据量很大的时候，优先使用方差过滤和互信息法调整，再上其他特征选择方法。使用逻辑回归时，优先使用嵌入法。使用支持向量机时，优先使用包装法。迷茫的时候，从过滤法走起，看具体数据具体分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
